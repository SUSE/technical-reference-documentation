:docinfo:
include::./common_docinfo_vars.adoc[]

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// General comments
// Keep in mind that this is a "getting started" guide and the
//   audience that you are trying to reach.
// Leverage ASCIIDoc features to make this document readable and usable:
//   - Text highlights (follow SUSE style guides)
//   - Admonitions (i.e., NOTE, TIP, IMPORTANT, CAUTION, WARNING)
//   - Code blocks
//   - Lists (ordered and unordered, as appropriate)
//   - Links (to other resources)
//   - Images
//     - Place image files under the ./media directory tree
//       (e.g., ./media/src/svg, ./media/src/png)
//     - Format preference: svg > png > jpg
//     - Consolidate images wherever possible
//       (i.e., don't use two images when one conveys the message)
//   - Use sections and subsections to organize and group related
//     steps.
// 
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Document attributes and variables
//
// NOTES:
// 1. Update variables below and adjust docbook file accordingly.
// 2. Comment out any variables/attributes not used.
// 3. Follow the pattern to include additional variables.
//
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// organization - do NOT modify
// -
:trd: Technical Reference Documentation
:type: Getting Started
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// document
// -
:title: Nvidia GPU Operator on BCI
:subtitle: Deploying the Nvidia GPU Kubernetes Operator on SLE15 Base Container Image

:product1: BCI
:product1_full: SUSE Linux Enterprise Base Container Image
:product1_version: SLE15 SP5
:product1_url: registry.suse.com/bci/bci-base-15sp5/index.html
:product2: RKE2
:product2_full: Rancher Kubernetes Engine 2
:product2_url: www.suse.com/products/rancher-kubernetes-engine/

:usecase: Nvidia GPU Operator on SLE BCI

:executive_summary: A brief statement of what this document provides (e.g., This document provides a brief introduction to implementing {usecase} with {product2_full} and {product1_full}.)
:executive_summary: This document describes the process of creating an Nvidia GPU Kubernetes operator container image based on SUSE Linux Enterprise Base Container Image
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// contributor
// specify information about authors, editors, and others here,
// then update docinfo file as appropriate
// -
:author1_firstname: Alex
:author1_surname: Arnoldy
:author1_jobtitle: Embedded Solutions Architect
:author1_orgname: SUSE Alliance Architects
//:author2_firstname: first (given) name
//:author2_surname: surname
//:author2_jobtitle: job title
//:author2_orgname: organization affiliation
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// miscellaneous
// define any additional variables here for use within the document
// -


// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


= {title}: {subtitle}



== Introduction

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a brief statement (1-4 sentences) of the purpose of the guide.
// This is could be the same as the executive summary.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This Getting Started guide provides comprehensive instructions for the creation of an OCI compliant container image containing the Nvidia GPU Kubernetes operator, and which is based on the SUSE Linux Enterprise 15 SP5 Base Container Image. The primary objective is to seamlessly integrate the Nvidia GPU operator, simplifying GPU management and support within Kubernetes clusters for GPU-intensive workloads. The choice of SUSE's SLE 15 SP5 Base Container Image is motivated by the unparalleled security certifications and enhanced supportability it offers, particularly when operating heterogeneous software stacks.

=== Motivation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a motivation for the document in 2-4 sentences to identify:
//   - what the document is about
//   - why it may be of interest to the reader (e.g., a use case)
//   - what products are being highlighted
// Include an approved SUSE | Partner logo lock-up if possible
// Include any additional, relevant details
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

The integration of the Nvidia GPU operator with the SUSE Linux Enterprise 15 SP5 Base Container Image provides a secure, certified, and supportable foundation for GPU-accelerated workloads. SUSE's SLE 15 SP5 Base Container Image is distinguished by a myriad of security certifications, including Common Criteria, FIPS, and EAL, making it a trusted choice for organizations with stringent security requirements.

Furthermore, users can confidently run diverse and complex software stacks without affecting the supportability of the base container image that is providing the Nvidia GPU operator. This ensures better stability and reliability for GPU-driven Kubernetes applications.

=== Scope

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Specify what this guide covers in no more than 2 sentences.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

//This guide will help you take the first steps to ...

This guide is dedicated to the process of creating OCI compliant container images that incorporate the Nvidia GPU operator within the SUSE Linux Enterprise 15 SP5 Base Container Image. Additionally, it provides instructions for deploying these container images within a Kubernetes cluster, specifically RKE2.

=== Audience

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify for whom this document is intended, perhaps with:
//   - topics of interests (e.g., machine learning, security, etc.)
//   - job roles (e.g., developer, administrator, platform architect, etc.)
//   - required skills
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

// This document is intended for ...

This guide caters to an audience comprising Kubernetes administrators, proficient DevOps practitioners, and application developers. It assumes a foundational understanding of Podman and/or Docker, Kubernetes, and Nvidia GPU technologies. This this guide should be suitable for most high technology professionals seeking to unlock the full potential of their GPU accellerated containerized applications.

== Prerequisites

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify minimum requirements (prerequisites) the reader
// would need in order to follow the steps of this guide.
// - Link to existing resources whenever possible.
// - Keep this section brief but elaborate as needed.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

Before embarking on the procedures outlined in this guide, it is imperative to ensure the fulfillment of the following prerequisites:

   1. Access to a SUSE Linux Enterprise 15 build host. It is highly recommended to ensure the build host is the same Service Pack version as the SLE BCI image that will be used. This guide will focus on SLE15 SP5.
   1. Podman installed on the host system.
   1. Availability of a Kubernetes cluster that includes at least one node with an Nvidia GPU. These instructions will focus on RKE2. 
   1. A basic familiarity with Docker and/or Podman, Kubernetes, and Nvidia GPU concepts.


== Technical overview

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a technical overview of the solution.
// - Identify components.
// - Describe how the components fit together.
//   Leverage diagrams as appropriate, including (but not limited to):
//   - component architecture
//   - data flow diagram
//   - workflow diagram
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

////
Resources:
https://gitlab.com/rdoxenham/driver/-/tree/main/sle15
https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html#suse15
https://docs.asciidoctor.org/asciidoc/latest/verbatim/source-blocks/
////

.Rough notes on process:

* Clone the Nvidia repository:

----
git clone https://gitlab.com/nvidia/container-images/driver && cd driver/sle15
----

* Can find the latest Data Center Driver for Linux x64 version at https://www.nvidia.com/en-us/drivers/unix/, or https://www.nvidia.com/download/index.aspx
** Copy the driver version number

* Update the Dockerfile: 
** Update `ARG CUDA_VERSION` to `12.1.1`
** Update `FROM registry.suse.com/bci/golang` to version `1.18`

NOTE: When using a SLE15 build host that has a different Service Pack version that the SLE BCI container image to be used, the SUSE software repositories for the host will be used. This means that packages that are installed into the container image will match the Service Pack version of the host, not the BCI container image. Ensure build host Service Pack matches the BCI container image to avoid this situation.

* Set these variables:

----
REGISTRY=""		# E.g. REGISTRY="local" or REGISTRY="registry.susealliances.com"
SLE15_SP_VERSION=""	# I.e. For SLE15 SP5, set to SP_VERSION="5"
DRIVER_VERSION=""	# E.g. DRIVER_VERSION="535.104.05"
DRIVER_TYPE=""		# I.e. "vgpu" or "passthrough"
----

* Build the container:

----
sudo podman build -t \
${REGISTRY}/nvidia-sle15sp${SLE15_SP_VERSION}-${DRIVER_VERSION} \
  --build-arg SLES_VERSION="15.${SLE15_SP_VERSION}" \   
  --build-arg DRIVER_TYPE="${DRIVER_TYPE}" \     
  --build-arg DRIVER_ARCH="x86_64" \     
  --build-arg DRIVER_VERSION="${DRIVER_VERSION}" \     
  --build-arg CUDA_VERSION="12.1.1" \   
  --build-arg PRIVATE_KEY=empty  \
.
----

* Remove the intermediate build container image that was created as part of the build process (and any other leftover artifacts):

----
for EACH in $(sudo podman images | awk '/none/ {print$3}'); do sudo podman rmi ${EACH}; done
----



This section offers a high-level explanation of the steps required to create OCI compliant container images with the Nvidia GPU Operator on the SUSE Linux Enterprise 15 SP5 Base Container Image.
Step 1: Repository Cloning

Begin by cloning the Nvidia GPU operator repository. This step ensures that you have the necessary source code to build the container image.
Step 2: Select the Appropriate Branch

Navigate to the 'sle15' branch within the cloned repository. This step ensures that you are working with the correct branch containing the relevant configurations for SUSE Linux Enterprise 15 SP5.
Step 3: Build OCI Compliant Container Images

Build OCI compliant container images with the Nvidia GPU Operator. This step is crucial for creating container images that include the Nvidia GPU Operator, making it accessible for use within your Kubernetes cluster.
Step 4: Kubernetes Cluster Preparation

Ensure your Kubernetes cluster, preferably RKE2, is configured with Nvidia GPU support and the necessary Nvidia drivers installed on the cluster nodes. This preparation step ensures that your cluster is ready to accommodate GPU-accelerated workloads.
Step 5: Deployment in Kubernetes

Craft a Kubernetes Deployment YAML file specifying the utilization of the Nvidia GPU Operator OCI compliant container image. Deploy this YAML to your Kubernetes cluster. This step enables you to run applications and workloads that can leverage GPU resources effectively.
Step 6: Validation

Access the active pod to validate GPU functionality. This validation step is crucial for ensuring that GPU resources are accessible within your Kubernetes pods and that GPU-accelerated tasks can be executed successfully.

By following these steps, you can create OCI compliant container images that integrate the Nvidia GPU Operator and deploy them within a Kubernetes cluster, enabling GPU-accelerated workloads with confidence. Detailed instructions for each step are provided in the full guide.



== Installation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Detail the steps of the installation procedure.
// The reader should be able to copy and paste commands to
// a local environment or follow along locally with screenshots.
// Include one or more verification steps to validate installation.
//
// Leverage:
// - Ordered lists
// - Code blocks
// - Screenshots
// - Admonitions
//
// If multiple installation methods are to be detailed, then
// - Create a summary list here
// - Detail each method in its own subsection.
//
// NOTE: For solutions involving SUSE Rancher, it is preferred
//       to detail two installation methods:
//       - Through the Rancher Apps Catalog with appropriate
//         screenshots and SUSE branding.
//       - A more manual approach (e.g., on the command-line).
//
// Complex configuration procedures may be broken out into one or more
// Configuration sections.
// These may be subsections of Installation or separate sections at
// the same level as Installation.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

Installation

    Clone the Nvidia GPU operator repository by executing the following command:

    bash

git clone https://gitlab.com/rdoxenham/driver.git

Navigate to the 'sle15' branch within the cloned repository:

bash

cd driver/sle15

Proceed to build OCI compliant container images with the following command:

bash

docker build -t sle15-nvidia-operator .

Confirm the successful creation of the OCI compliant container image by executing:

bash

    docker images

    The listing should display the 'sle15-nvidia-operator' image.

Deployment in Kubernetes (RKE2)

    Ensure the Kubernetes cluster, preferably RKE2, is suitably configured with Nvidia GPU support and the essential Nvidia drivers installed on the cluster nodes.

    Craft a Kubernetes Deployment YAML file, detailing the utilization of the Nvidia GPU operator OCI compliant container image, as exemplified below:

    yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gpu-app
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: my-gpu-app
    spec:
      containers:
      - name: my-gpu-container
        image: sle15-nvidia-operator
        resources:
          limits:
            nvidia.com/gpu: 1  # Adjust GPU resource allocation as necessitated

Deploy the articulated Deployment YAML to the Kubernetes cluster via the following command:

bash

kubectl apply -f my-gpu-app-deployment.yaml

Ascertain the operational status of the deployment by issuing the command:

bash

kubectl get pods

The resulting list should feature the 'my-gpu-app' pod in the 'Running' state.



== Validation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Illustrate functionality with a demonstration.
// Begin with a description or outline of the demonstration.
// Provide clear steps (in ordered lists) for the reader to follow.
// Typical demonstration flow is:
// 1. Prepare the environment for the demonstration.
//    This should be minimal, such as downloading some data to use.
//    If this requires more than a couple steps, consider putting it
//    in a subsection.
// 2. Perform the demonstration.
//    Be careful not to overuse screenshots.
// 3. Verify.
//    This may be interwoven into performing the demonstration.
//
// As with Installation, leverage ordered lists, code blocks,
// admonitions, and screenshots.
//
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

1. Gain access to the active pod to conduct a comprehensive validation of GPU functionality:


1. kubectl exec -it my-gpu-app-<pod-id> -- /bin/bash

1. Within the pod's context, employ Nvidia tools such as 'nvidia-smi' to meticulously scrutinize GPU-related metrics and execute tasks necessitating GPU capabilities.

1. Execute comprehensive tests of GPU-intensive workloads or applications within the pod to substantiate the unimpeded access and optimal utilization of GPU resources.



== Summary

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Summarize:
// - Motivation (1 sentence)
// - What was covered (1-2 sentences)
// - Next steps (unordered list of 2-4 further learning resources)
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

// In this guide, you learned ...

This guide has effectively steered the creation of OCI compliant container images rooted in the SUSE Linux Enterprise 15 SP5 Base Container Image, incorporating the Nvidia GPU operator. Furthermore, it has provided coherent instructions for the seamless deployment of these images within a Kubernetes cluster, specifically RKE2. The ensuing utilization of this integrated solution is aimed at affording containerized applications GPU-acceleration, thus enhancing computational performance and efficiency.

The strategic choice of SUSE's SLE 15 SP5 Base Container Image as the foundation for this integration underscores the commitment to security, certifications, and supportability. Organizations with exacting security requirements will find solace in the numerous certifications such as Common Criteria, FIPS, and EAL. Additionally, the enhanced support for heterogeneous software stacks guarantees the reliability and stability of GPU-accelerated applications running on this foundation.

This holistic approach to GPU management within containerized landscapes is poised to augment the capabilities of developers and system administrators alike, fostering innovation and operational excellence. For further insights and updates pertaining to the Nvidia GPU operator and its multifaceted functionalities, kindly refer to the official Nvidia documentation and the designated repository mentioned within this guide.

A pivotal point to underscore is the indispensability of a Kubernetes cluster, preferably RKE2, that is provisioned with Nvidia GPU support and the requisite Nvidia drivers to fully harness GPU resources when deploying containers integrated with the aforementioned OCI compliant container images.

For an exhaustive comprehension of advanced configurations and nuanced details, the consultative resources made available by SUSE, Docker, Nvidia, and RKE2 are strongly recommended.




// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Do not modify below this break.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

++++
<?pdfpagebreak?>
++++


:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
