:docinfo:
include::./common_docinfo_vars.adoc[]

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// General comments
// Keep in mind that this is a "getting started" guide and the
//   audience that we are trying to reach.
// Leverage ASCIIDoc features to make this document readable and usable:
//   - Text highlights (follow SUSE style guides)
//   - Admonitions (i.e., NOTE, TIP, IMPORTANT, CAUTION, WARNING)
//   - Code blocks
//   - Lists (ordered and unordered, as appropriate)
//   - Links
//   - Images
//     - Place image files under the ./media directory tree
//       (e.g., ./media/src/svg, ./media/src/png)
//     - Format preferences: svg > png > jpg
//     - Consolidate images wherever possible;
//       that is, prefer text over images
//   - Sections and subsections to organize content and break up actions
// 
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Variables & Attributes
// Follow indicated patterns.
//   E.g., "Ondat data plane with SUSE Rancher"
//         "Grace Hopper, Engineer, US Navy"
//         "SUSE Linux Enterprise Server 15 SP4"
//         "SUSE Rancher 2.6"
// NOTE: Some variables & attributes have been deprecated and
//       have been commented out below.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

:title: MinIO Object Storage for SUSE Rancher : Getting Started
:productname: SUSE Rancher 2.6
:partnerproductname: MinIO
:author1: Ravind, Kumar, Technical Writer, MinIO
:author2: Terry Smith, Global Partner Solutions Director, SUSE
:author3: Samip Parikh, Partner Solutions Architect, SUSE
//:revdate: Month dd, YYYY
//:revnumber: YYYYmmdd
//:toc2:
//:toc-title: {title}
//:toclevels: 4


= {title}



== Introduction

=== Motivation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// In this section, provide motivation for the document.
// Provide a brief statement (2-4 sentences) to identify
//   - what products are being highlighted
//   - what the document is about and why it may be of
//     interest to the reader and beyond.
// Include an approved SUSE | Partner logo lock-up
// Include additional details if needed, like
//    - the challenges that are or can be addressed
//    - specific benefits of this solution
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


// logo lock-up
image::logo-lockup_suse-minio_hor_dark.svg[scaledwidth="65%", align="center"]


Kubernetes and object storage have fundamentally changed the modern application landscape, promising advantages of scale, agility, and efficiency that were impossible with monolithic application models and legacy architectures.
Modern applications are cloud-native.
They are containerized, data-rich, and designed to run everywhere at hyperscale.
But to achieve cloud native goals, you need the right tools.


https://www.suse.com/products/suse-rancher/[SUSE Rancher] is the enterprise Kubernetes and container management platform that simplifies and unifies multi-cluster management, enabling consistent operations, workload management, and enterprise-grade security across your entire Kubernetes landscape - on-premises, in the cloud, and at the edge. 
 
https://min.io/product/multicloud-suse-rancher[MinIO] provides Kubernetes-native, consistent, performant, and scalable object storage.  MinIO is S3-compatible, ensuring a familiar API workspace for an entire ecosystem of developers and software platforms.  MinIO natively integrates with SUSE Rancher and the Rancher toolchain, such as the kubectl CLI and the Istio service mesh, enabling infrastructure and DevOps teams with streamlined storage operations across multiple clouds and at the edge. 
 
The combination of MinIO with SUSE Rancher empowers enterprises with a powerful, easy-to-use solution to scale and consistently manage applications across any multi-cloud and hybrid-cloud infrastructure.


=== Scope

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Specify what this guide covers in no more than 2 sentences.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This guide will introduce you to some general concepts and basic steps for installing, configuring, and using MinIO Object Storage in a SUSE Rancher Kubernetes environment.

Additionally, you will get a general framework for connecting Spark, Presto, or other AI/ML platforms with support for the S3A connector to MinIO for high performance, scalable data workloads within Kubernetes.



=== Audience

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify for whom this document is intended, perhaps with:
//   - Topics of interests
//   - Potential job roles
//   - Required skills <- This can be critically important
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This document is intended for DevOps, IT Professionals, application administrators, and developers who are responsible for building, managing, and using cloud-native object storage resources.



== Technical overview

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a technical overview of the solution.
// Identify components.
// Describe how the components fit together.
// Leverage diagrams as appropriate, including (but not limited to):
//   - component architecture
//   - data flow
//   - workflow
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


MinIO makes it easy to deliver robust object storage for Kubernetes-native applications running in your SUSE Rancher environment.
The MinIO Operator is the key, deploying and managing the MinIO tenant to which your applications connect.
Your MinIO tenant leverages storage locally attached to worker nodes.
You can use a variety of storage types, such as public cloud storage, spinning hard disks, and fast solid-state storage, to enable data tiering to satisfy workload and business use cases.
And MinIO for SUSE Rancher supports use of external encryption key management, identity management, monitoring and alerting, logging and auditing, and more.

// architecture diagram
image::gs_rancher_minio_architecture.svg[scaledwidth="85%", align="center"]


Getting started with MinIO for SUSE Rancher is pretty easy.
In general, the process is as follows:

. Log into your SUSE Rancher environment and select a managed cluster.
Deploying or importing Kubernetes clusters is covered elsewhere.
A good place to start is the https://rancher.com/docs/rancher/v2.6/en/[Rancher documentation].

. Install the https://krew.sigs.k8s.io/docs/user-guide/setup/install/[krew] utility.

. Create persistent volumes.
Persistent volumes (PVs) are the storage backing for the MinIO object store.

. Install MinIO Operator.
The MinIO Operator supports deploying and managing MinIO tenants and automatically generates a persistent volume claim (PVC) for each volume.

. Deploy a MinIO tenant.
The MinIO tenant represents an object store to which an application can be granted access.

. Connect to the MinIO tenant.
The MinIO tenant is exposed as a Kubernetes service to which application workloads can connect.


== Prerequisites

This guide assumes that you have access to an existing Kubernetes cluster managed by https://rancher.com/docs/rancher/v2.6/en/overview/[SUSE Rancher].
This cluster should have at least four (4) worker nodes for scheduling MinIO pods and services.

While MinIO is hardware agnostic and can function on consumer-grade hardware, the following recommendations for each worker node provide a baseline for high performance object storage:

* 8 vCPU cores:
CPU availability primarily affects performance related to hashing and encryption operations, including TLS connections.

* 128 GB of available (unused) RAM:
Memory primarily affects the number of simultaneous network connections per pod. 
* 25 GbE Network Interface Card (NIC):
Network is a primary performance factor and is most likely to constrain performance if throughput cannot satisfy the total aggregated storage of the MinIO tenant.

* Locally-attached storage drives (NVMe, SSD, HDD):
Ensure all drives intended for use by the MinIO tenant are the same type and capacity (e.g., 4 TB NVMe drives) for consistent performance.
MinIO should have exclusive access to these drives for best results.

[TIP]
====
Be sure drives are provisioned in JBOD (Just a Bunch of Disks) mode with no RAID, ZFS Pooling, or other redundancy or resiliency or tooling layers.
MinIO implements https://docs.min.io/minio/baremetal/concepts/erasure-coding.html[erasure coding] to provide object-level healing and resiliency with less overhead than adjacent technologies, such as RAID or replication.
====


The MinIO Operator enforces the following requirements for each tenant:

* The tenant must consist of at least 4 servers (4 MinIO pods).

* The tenant must consist of at least 1 disk per server.

* The worker nodes must have at least 2 GiB of RAM available per MinIO pod.


The worker nodes must have sufficient local PVs and capacity to support the number of drives in the deployment plus two additional drives for the LogSearch and Prometheus pods.
For example, deploying a tenant with 16 drives requires 18 persistent volumes.



== Create persistent volumes

Before proceeding, review the concepts of persistent volumes (PVs), persistent volume claims (PVCs), and storage classes in the https://rancher.com/docs/rancher/v2.6/en/cluster-admin/volumes-and-storage/how-storage-works/[Rancher documentation].

[TIP]
====
MinIO strongly recommends using direct-attached storage on each worker node.
====


The MinIO Operator generates PVCs for each storage resource required by the tenant.
When creating a MinIO tenant, you specify the storage class to assign to each PVC.
Kubernetes must bind each generated PVC to a PV with matching storage class for the tenant to successfully start.

In this guide, you will use MinIO DirectPV to automatically generate and manage local PVs.
For those clusters where DirectPV cannot be used, local PVs can be https://docs.min.io/minio/k8s/tenant-management/deploy-minio-tenant.html[manually provisioned].


https://min.io/directpv[MinIO DirectPV] is a CSI driver that manages locally attached storage and automatically provisions PVs to match incoming PVCs from stateful application.
It is designed to be lightweight and scalable to tens of thousands of drives.


DirectPV is installed with https://krew.sigs.k8s.io/[Krew], the plugin manage for the `kubectl` command.
If you do not already have it on your system, https://krew.sigs.k8s.io/docs/user-guide/setup/install/[install Krew] before proceeding.


Once you have Krew installed, you can install DirectPV with the following steps:

. Install the DirectPV `kubectl` plugin.
+
[source, bash]
----
kubectl krew install directpv
----

. Use the plugin to install DirectPV into your Kubernetes cluster.
+
[source, bash]
----
kubectl directpv install
----

. Verify that DirectPV has successfully started.
+
[source, bash]
----
kubectl directpv info
----

. List available drives in your cluster.
+
[source, bash]
----
kubectl directpv drives ls
----
+
[NOTE]
====
DirectPV requires unformatted storage volumes and automatically excludes any formatted drives, including those used by an operating system.
====


At this point, you can use DirectPV to format and manage the drives in your cluster nodes.

For example, format all available drives on nodes kubeworker1, kubeworker2, kubeworker3, and kubeworker4 with:

[source, bash]
----
kubectl directpv drives format --nodes kubeworker{1...4}
----

You can also be more specific about which drives to format:

[source, bash]
----
kubectl directpv drives format --drives /dev/sd{a...e} --nodes kubeworker{1...4}
----


Use the `kubectl directpv drives ls` command to view the status of the drives:

[source, bash]
----
kubectl directpv drives ls

 DRIVE  	CAPACITY        ALLOCATED  FILESYSTEM        VOLUMES  NODE                   ACCESS-TIER  STATUS 	 
 /dev/sda2  1  TiB        -      	LVM2_member       -    	kubecontroller.local  -        	Available    
 /dev/sda2  1  TiB	-      	LVM2_member       -    	kubeworker1.local 	    -        	Available   
 /dev/sdb   7.68 TiB	-      	xfs      	-    	kubeworker1.local 	    -        	Ready  	 
 /dev/sdc   7.68 TiB	-      	xfs      	-    	kubeworker1.local 	    -        	Ready  	 
 /dev/sdd   7.68 TiB	-      	xfs      	-    	kubeworker1.local 	    -        	Ready  	 
 /dev/sde   7.68 TiB	-      	xfs      	-    	kubeworker1.local 	    -        	Ready  	 
 /dev/sda2  1 TiB	         -      	LVM2_member  -    	kubeworker2.local 	    -        	Available   
 /dev/sdb   7.68 TiB	-      	xfs      	-    	kubeworker2.local 	    -        	Ready  	 
 /dev/sdc   7.68 TiB	-      	xfs      	-    	kubeworker2.local 	    -        	Ready  	 
 /dev/sdd   7.68 TiB	-      	xfs      	-    	kubeworker2.local 	    -        	Ready  	 
 /dev/sde   7.68 TiB	-      	xfs      	-    	kubeworker2.local 	    -        	Ready  	 
 /dev/sda2  1  TiB	-      	LVM2_member  -    	kubeworker3.local 	    -        	Available   
 /dev/sdb   7.68 TiB	-      	xfs      	-    	kubeworker3.local 	    -        	Ready  	 
 /dev/sdc   7.68 TiB	-      	xfs      	-    	kubeworker3.local 	    -        	Ready  	 
 /dev/sdd   7.68 TiB	-      	xfs      	-    	kubeworker3.local 	    -        	Ready  	 
 /dev/sde   7.68 TiB	-      	xfs      	-    	kubeworker3.local 	    -        	Ready  	 
 /dev/sda2  1  TiB	-      	LVM2_member  -    	kubeworker4.local 	    -        	Available   
 /dev/sdb   7.68 TiB	-      	xfs      	-    	kubeworker4.local 	    -        	Ready  	 
 /dev/sdc   7.68 TiB	-      	xfs      	-    	kubeworker4.local 	    -        	Ready  	 
 /dev/sdd   7.68 TiB	-      	xfs      	-    	kubeworker4.local 	    -        	Ready  	 
 /dev/sde   7.68 TiB	-      	xfs      	-    	kubeworker4.local 	    -        	Ready  
----

[NOTE]
====
Drives marked as `Ready` are managed and DirectPV will respond to any persistent volume claim with a storage class of 'directpv-min-io'.
====



== Deploy the MinIO Operator

MinIO is designed to simplify the installation process.  In a bare metal environment, you can deploy a large distributed MinIO cluster using just the MinIO binaries and a handful of environment variables.

In a Kubernetes environment, provisioning large stateful services requires more care as the full lifecycle and behavior of pods, networking, and other transient resources come into play. The MinIO Kubernetes Operator extends the Kubernetes API to support deploying MinIO Tenants via the Operator Console GUI or using the `kubectl minio` plugin. The Operator fully manages all underlying operations associated with deploying and managing Kubernetes resources, allowing operators, administrators, and developers to focus on deploying and using their object storage resource.

Use one of the following methods to install the MinIO Operator onto a Rancher-managed Kubernetes cluster:

* SUSE Rancher Apps & Marketplace.
* MinIO Operator plugin.
* MinIO Helm chart.


=== SUSE Rancher Apps & Marketplace


=== MinIO Operator plugin


=== MinIO Helm chart


== Deploy the MinIO tenant



== Connect to the MinIO tenant




== Summary

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Summarize what was covered, including:
//   - Motivation
//   - Installation
//   - Demonstration
// Include any hints about other capabilities.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =




== Additional resources

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide any additional resources that may help the reader
//   continue to explore this topic.
// Use an unordered list for references.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =





// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Do not modify below this break.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

++++
<?pdfpagebreak?>
++++


:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
