:docinfo:
include::./common_docinfo_vars.adoc[]

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// General comments
// Keep in mind that this is a "getting started" guide and the
//   audience that you are trying to reach.
// Leverage ASCIIDoc features to make this document readable and usable:
//   - Text highlights (follow SUSE style guides)
//   - Admonitions (i.e., NOTE, TIP, IMPORTANT, CAUTION, WARNING)
//   - Code blocks
//   - Lists (ordered and unordered, as appropriate)
//   - Links (to other resources)
//   - Images
//     - Place image files under the ./media directory tree
//       (e.g., ./media/src/svg, ./media/src/png)
//     - Format preference: svg > png > jpg
//     - Consolidate images wherever possible
//       (i.e., don't use two images when one conveys the message)
//   - Use sections and subsections to organize and group related
//     steps.
//
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Variables & Attributes
//
// NOTES:
// 1. Update variables below and adjust docbook file accordingly.
// 2. Comment out any variables/attributes not used.
// 3. Follow the pattern to include additional variables.
//
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// organization - do NOT modify
:trd: Technical Reference Documentation
:type: Getting Started
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// document and product
:title: Edge Analytics in Healthcare
:subtitle: Cancer Prediction System
:productname: Rancher 2.6
:platform1: SUSE Rancher 2.6
:platform2: SUSE Linux Enterprise Server 15 SP3
:otherproduct1: Cancer Prediction System
:usecase: edge analytics in healthcare
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// authors
:author1_firstname: Abhinav
:author1_surname: Sharma
:author1_jobtitle: Google Summer of Code 2022 Contributor
:author1_orgname: openSUSE
// :author1_email: abhinavsharma332@gmail.com
// additional contributors:
// - Bryan Gartner, bryan.gartner@suse.com
// - Brian Fromme, brian.fromme@suse.com
// - Ann Davis, andavis@suse.com
// - Terry Smith, terry.smith@suse.com
// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// define any additional variables here for use within the document
:k8s: K3s 1.21.3+k3s1
:storage: Longhorn 1.3.1

// - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


= {title}

== Introduction

=== Motivation

//image::gsoc_intro_banner.png[Analytics Edge Ecosystem Workloads - Google Summer of Code, align="center"]

Cancer is the world's second leading cause of death in the world.
It results in development of abnormal cells that divide uncontrollably and can infiltrate and destroy normal body tissue.
Survival rates are improved through better screening, treatment, and prevention.

Advanced analytics and machine learning (ML) continue to have a growing influence on modern medicine, accelerating diagnosis, developing treatments, and improving results.
Analytics in healthcare is not only taking place in data centers.
Increasingly, analytics and ML are deployed at the edge - in clinics, in https://en.wikipedia.org/wiki/CT_scan[CT] imaging systems and other devices, and even in mobile computing devices, like your doctor's tablet.
This is made possible with modern container technologies, like https://kubernetes.io/[Kubernetes], which is a portable, extensible, open source platform for managing containerized workloads and services.


In medicine and many other fields, analytics at the edge makes sense.
This is where the data, so critical to analytics and ML, is located.
And this is where medical professionals interact with patients.
This is where they save lives.


This project, resulting in the {otherproduct1}, is part of the 2022 https://summerofcode.withgoogle.com/[Google Summer of Code], a global mentoring program focused on introducing new contributors to open source software development.
Google Summer of Code contributors are paired with mentors from open source organizations, such as https://suse.com/[SUSE]. They learn from these experienced open source developers, gain exposure to real-world software development techniques, and write code for real-world challenges.
This project was developed under mentorship of Bryan Gartner, Ann Davis, and Brian Fromme of https://suse.com/[SUSE].

This document reviews the approach, implementation, and deployment of this ML-based, Cancer Predicition System, designed to assist medical professionals in early screening.




=== Scope

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Specify what this guide covers in no more than 2 sentences.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This guide introduces the basic concepts and steps to install, configure, and use the {otherproduct1} in a SUSE Rancher Kubernetes environment.


=== Audience

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify for whom this document is intended, perhaps with:
//   - Topics of interests
//   - Potential job roles
//   - Required skills <- This can be critically important
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This guide is intended for data scientists, data engineers, and data analysts. It also addresses radiologists, doctors, and hospital administrators who are interested in learning more about the technologies that enable analytics and ML at the edge, particularly for medical use cases.
To get the most out of this guide, you should have basic familiarity with the Linux command line and Kubernetes concepts and tooling.


== Technical overview

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a technical overview of the solution.
// Identify components.
// Describe how the components fit together.
// Leverage diagrams as appropriate, including (but not limited to):
//   - component architecture
//   - data flow
//   - workflow
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


Cancer Predicition System is an ML-based application stack with the goal to assist in cancer risk assessment by predicting the likelihood of developing a cancer prior to occurence of the disease.
The image below illustrates the general architecture of the {otherproduct1}.

image::edge-analytics_healthcare_architecture.png[Cancer Prediction System Architecture, align="center", scaledwidth="80%"]

The {otherproduct1} uses CT scan images in the https://www.dicomstandard.org/[Digital Imaging and Communications in Medicine] (DICOM) standard.
The system is designed to be deployed in a microservices architecture and is divided into four interfaces:

* Lab Technician Dashboard
* Doctor Dashboard
* ML Pipeline Dashboard
* Rancher Dashboard


=== Deployment architecture

The {otherproduct1} supports a broad spectrum of deployment architectures.

For this guide, the {otherproduct1} is deployed on a lightweight Kubernetes cluster, featuring {k8s}.
The cluster is managed by {productname}, and persistent storage is provided through {storage}.


All nodes have the following characteristics:

* Processor: 2 vCPUs

* Memory: 4 GB RAM

* Storage: 10 GB (available)

* Operating system: {platform2}


// This image should reflect the architecture used.
// image::rancherk3s.png[K3s Architecture, align="center", scaledwidth=80%]
 

=== Components and tools

// retain in case needed:
// Kubernetes version: v1.21.3+k3s1
// Rancher version: v2.6.0
// Longhorn version: v1.2.0 <-- are you sure?
// Kustomize version: v4.1.3
// Kubectl version: v1.21.3
// Docker version: 20.10.7

The {otherproduct1} uses a variety of components and tools.

Some highlights include:

Docker:: https://www.docker.com/[Docker] is a platform that enables developers to build, deploy, run, and manage application containers.
This guide uses Docker 20.10.7.

Flask:: https://flask.palletsprojects.com/en/2.2.x/[Flask] is a lightweight Web framework written in Python to easily create Web applications.
Flask is used to serve the back-end and ML models as https://en.wikipedia.org/wiki/API[APIs].

Helm:: https://helm.sh/[Helm] is a package manager for Kubernetes that helps you define, install, upgrade, and share Kubernetes applications.

K3s:: https://k3s.io/[K3s] is a lightweight, CNCF-certified Kubernetes distribution built for IoT and edge computing.

Keras:: https://keras.io/[Keras] is an open source software library that provides a high-level, Python API for designing artificial neural networks.
It acts as an interface to the https://www.tensorflow.org/[TensorFlow 2] framework.
Keras is used to implement the https://www.tensorflow.org/tutorials/images/cnn[Convolutional Neural Nets (CNNs)] in the {otherproduct1}.
// Add version here

Kubectl:: https://kubernetes.io/docs/reference/kubectl/[Kubectl] is a command line tool for communicating with a Kubernetes cluster's control plane via the Kubernetes API.

Kubeflow:: https://www.kubeflow.org/[Kubeflow] is dedicated to making deployments of ML workflows on Kubernetes simple, portable, and scalable.
It is used to define ML pipelines and to orchestrate workflows

Kustomize:: https://github.com/kubernetes-sigs/kustomize[Kustomize] is a template-free way to programmatically customize Kubernetes objects and is both a stand-alone tool and built into Kubectl.

Longhorn:: https://longhorn.io/[Longhorn] is a cloud-native, distributed, persistent block storage system for Kubernetes.

Manifests:: A manifest is a text file (in JSON or YAML format) that specifies the desired state of an https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/[object that Kubernetes will maintain].
Manifests are used by Kustomize and can be applied with Kubectl.

SUSE Rancher:: https://rancher.com/[Rancher] is an enterprise-grade, Kubernetes cluster management platform.


=== Process

Getting started with the {otherproduct1} is fairly easy.
In general, the process is as follows:

. Prepare your Kubernetes cluster.

. Clone the project repository.
+
[source,bash]
----
git clone https://github.com/abhi-bhatra/ct_image_scanning.git
----

. Create or update the Kubernetes manifests to define the application environment and deployment.

. Log in to your SUSE Rancher environment and select the Kubernetes cluster that will host the application.

. Apply Kubernetes manifests to set up the environment (namespaces and storage).

. Apply Kubernetes manifests to deploy the application.

. Access the application via the Rancher Dashboard.



== Prepare the Kubernetes cluster

=== Access the Rancher environment

It is assumed that you already have access to deploy applications to a Kubernetes cluster.
If you need to set up your cluster environment, these references may help:

* https://docs.ranchermanager.rancher.io/how-to-guides/new-user-guides/kubernetes-cluster-setup/k3s-for-rancher[Setting up a high-availability K3s Kubernetes cluster for Rancher].

* https://documentation.suse.com/trd/kubernetes/single-html/kubernetes_ri_rancher-k3s-sles/[Introductory deployment of SUSE Rancher].

* https://docs.ranchermanager.rancher.io/pages-for-subheaders/installation-and-upgrade[Installing / Upgrading Rancher].

* https://medium.com/@abhinavsharma332/deploy-single-node-cluster-using-k3s-or-rke-6fc9e6a38b66[Deploying single node cluster using K3s or RKE].


When you are ready, log in to the Rancher UI with your Web browser.


image::edge-analytics_healthcare_rancher_portal.png[Rancher Portal, align="center", scaledwidth="80%"]


=== Install Longhorn

Before proceeding, review the concepts of persistent volumes, persistent volume claims (PVCs), and storage classes in the https://rancher.com/docs/rancher/v2.6/en/cluster-admin/volumes-and-storage/how-storage-works/[Rancher documentation].

https://longhorn.io/[Longhorn] is a lightweight distributed block storage solution for Kubernetes that is easy to use, self-healing, and highly available.
With Longhorn, you can:

* partition your block storage into persistent volumes for stateful applications.

* replicate block storage across multiple nodes and data centers to increase availability.

* schedule recurring snapshots of a volume and recurring backups to external storage.

* restore volumes from backup.

* create cross-cluster disaster recovery volumes.


Install Longhorn into your Kubernetes cluster using one of the following three methods:

. https://longhorn.io/docs/1.3.1/deploy/install/install-with-rancher/[Using the Apps and Marketplace in Rancher UI]
+
image::edge-analytics_healthcare_longhorn_marketplace.png[Longhorn, scaledwidth="80%", align="center"]

. https://longhorn.io/docs/1.3.1/deploy/install/install-with-kubectl/[Using Kubectl manifest files]
+
[source, bash]
----
kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.3.1/deploy/longhorn.yaml
----

. https://longhorn.io/docs/1.3.1/deploy/install/install-with-helm/[Using Helm]:
+
[source, bash]
----
helm repo add longhorn https://charts.longhorn.io
helm repo update
helm install longhorn/longhorn -name longhorn -namespace longhorn-system
----


After successfull installation, you can use the Longhorn Dashboard to manage and monitor the cluster's Longhorn volumes.
Access the Longhorn Dashboard through the Rancher UI.

. In the Rancher UI, select the cluster where Longhorn is installed.

. In the left navigation menu, click __Longhorn__.

. Click __Longhorn__ in the __Overview__ section to access the Longhorn UI.


image::edge-analytics_healthcare_longhorn_dashboard.png[Longhorn Dashboard, scaledwidth="85%", align="center"]



=== Provision persistent storage

You can provision persistent storage for your applications with `kubectl` or by using the Longhorn UI.
See the https://longhorn.io/docs/1.3.1/volumes-and-nodes/create-volumes/[Longhorn documentation] for additional details.

The steps below leverage `kubectl` to provision PersistentVolumeClaims for two PersistentVolumes.

. Create a PersistentVolumeClaim for the applications to share data and information in the cluster.

.. Create the file 'data-pvc.yaml'.
+
[listing]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-pvc
  namespace: cancerns
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: longhorn
----  

.. Implement this PersistentVolumeClaim.
+
[source, bash]
----
kubectl apply -f data-pvc.yaml
----

. Create a PersistentVolumeClaim for the data volume.

.. Create the file 'ds-pvc.yaml'.
+
[listing]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ds-pvc
  namespace: cancerns
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: longhorn
----

.. Implement this PersistentVolumeClaim.
+
[source, bash]
----
kubectl apply -f ds-pvc.yaml
----


. You can review the persistent volumes in the Rancher UI.
+
image::edge-analytics_healthcare_persistent-volumes.png[PVC, scaledwidth="85%", align="center"]



=== Install Kubeflow Pipelines

The Kubeflow project provides a straightforward way to deploy and automate ML workflows on Kubernetes, making it simple, portable, and scalabe.
Anywhere you are running Kubernetes, you should be able to run Kubeflow.
The https://www.kubeflow.org/docs/started/[Kubeflow documentation] provides detailed instructions to install Kubeflow on Kubernetes for production deployments.

Typically, Kubeflow is installed into a large production environment, where it can rely on shared services, like https://istio.io/[Istio] service mesh.
For this guide, you can use https://www.kubeflow.org/docs/components/pipelines/v1/installation/standalone-deployment/[Kubeflow Pipelines].
This stand-alone implementation of Kubeflow does not dependend on other services, providing a simpler installation process.

[NOTE]
====
Kubeflow Pipelines does not support multi-user separation and may not be suitable for production environments.
====


. Set the PIPELINE_VERSION and apply the Kubeflow Pipelines manifest:
+
[source, bash]
----
export PIPELINE_VERSION=1.8.3

kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION"

kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io

kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=$PIPELINE_VERSION"
----
+
[NOTE]
====
It can take several minutes to deploy Kubeflow Pipelines on your cluster.
====

. Check the status of the deployment by watching the output of:
+
[source, bash]
----
kubectl get all -n kubeflow
----
STATUS of all pods is 'Running' once all services have started.
+
[source, bash]
----
NAME                                                   READY   STATUS             RESTARTS   AGE
pod/workflow-controller-5667759dd7-fbgrp               1/1     Running            0          2d3h
pod/ml-pipeline-scheduledworkflow-7f8bc78db9-qpx4f     1/1     Running            0          2d3h
pod/ml-pipeline-viewer-crd-8497d9695c-tqmdg            1/1     Running            0          2d3h
pod/ml-pipeline-ui-69bc756bd7-nmzm6                    1/1     Running            0          2d3h
pod/metadata-envoy-deployment-6df8bdd989-lc77p         1/1     Running            0          2d3h
pod/minio-5b65df66c9-qt6lk                             1/1     Running            0          2d3h
pod/ml-pipeline-persistenceagent-585c4b58d6-mcmtx      1/1     Running            1          2d3h
pod/ml-pipeline-7cc4f8fdf7-b2vjp                       1/1     Running            2          2d3h
pod/cache-server-6cddbbc849-bnd6n                      1/1     Running            1          2d3h
----

. Verify the installation by accessing the Kubeflow Pipelines dashboard.

.. On the command line, create a port forward for the 'ml-pipeline-ui' service.
+
[source, bash]
----
kubectl port-forward -n kubeflow svc/ml-pipeline-ui 8080:80
----

.. Log in to the Rancher UI with your Web browser.

.. Select your cluster, then click __Services__.

.. Click the port indicated for the 'ml-pipeline-ui' service.
+
image::edge-analytics_healthcare_select_ml_port.png[Kubeflow Pipelines Port Selection, scaledwidth="80%"]

.. Your browser should open to the Kubeflow Pipelines dashboard.
+
image::edge-analytics_healthcare_kubeflow_1.png[Kubeflow Pipelines dashboard, scaledwidth="80%"]



== Download the data

image::edge-analytics_healthcare_dataset.jpg[Dataset, scaledwidth="85%", align="center"]

https://www.cancerimagingarchive.net/[The Cancer Imaging Archive (TCIA)] is a service that de-identifies and hosts a large archive of medical images of cancer accessible for public download.

[NOTE]
====
* Albertina, B., Watson, M., Holback, C., Jarosz, R., Kirk, S., Lee, Y., â€¦ Lemmerman, J. (2016). Radiology Data from The Cancer Genome Atlas Lung Adenocarcinoma [TCGA-LUAD] collection. The Cancer Imaging Archive. http://doi.org/10.7937/K9/TCIA.2016.JGNIHEP5

* Clark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057. (paper)
====


The {otherproduct1} uses the subset of TCIA images that were featured in a https://www.kaggle.com/datasets/kmader/siim-medical-images[Kaggle competition].
This dataset is designed to allow testing of different methods for examining trends in CT image data associated with using contrast and patient age.
It consists of 475 series of CT images from 69 participants where valid age, modality, and contrast tags could be found.

. Download the dataset from https://www.kaggle.com/datasets/kmader/siim-medical-images as a 262 MB ZIP archive.
+
[NOTE]
====
You need a free Kaggle account to download the dataset.
====

. Extract the archive and examine its directory structure and contents.
+
[listing]
----
/dataset
-- archive/
   -- dicom_dir/
   ...
   ID_0001_AGE_0069_CONTRAST_1_CT.dcm
   ...
   -- tiff_images/
   ...
   ID_0000_AGE_0060_CONTRAST_1_CT.tif
   ...
   -- full_archive.npz
   -- overview.csv
   
-- dataset-classification
   -- Chest-CT/
   -- NonChest-CT/

-- dataset-prediction/
   -- train/
      -- cancer/
      -- non-cancer/
   -- test/
      -- cancer/
      -- non-cancer/
   -- validation/
      -- cancer/
      -- non-cancer/
----
+
* archive: Contains the raw dataset downloaded from Kaggle.
This is further processed for use in the machine learning model.

* dataset-classification: Contains a separate dataset, where all the DICOM images are classified as chest and non-chest.
Only chest DICOM images are used for this model, so non-chest images must be filtered out.

* dataset-prediciton: Contains all the images separated into train, test, and validation subsets.
Each image is labeled as 'cancer' or 'non-cancer'.

. Now apply the dataset deployment manifests to download and extract the dataset into the data volume on your cluster.
+
[listing]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datasetvm
  namespace: cancerns
spec:
  replicas: 1
  selector:
    matchLabels:
      app: datasetvm
  template:
    metadata:
      labels:
        app: datasetvm
    spec:
      containers:
      - name: datasetvm
        image: "ubuntu:latest"
        imagePullPolicy: Always
        volumeMounts:
        - name: dataset
          mountPath: /dataset
        env:
        - name: DATASET
          value: "https://rancherdataset.blob.core.windows.net/ct-images/dataset.zip"
        command: ["/bin/sh","-c"]
        args: ["apt-get update; apt-get install unzip wget -y; wget $DATASET -O /dataset/dataset.zip; unzip /dataset/dataset.zip -d /dataset/dataset; ls -l /dataset/dataset"]
      volumes:
      - name: dataset
        persistentVolumeClaim:
          claimName: ds-pvc
----


== Machine learning model

The {otherproduct1} aims to assist a doctor in identifying the probability of cancer in a patient based on a CT image.
That is, the {otherproduct1} must classify a CT image as indicative of cancer or not indicative of cancer.
This classification problem can be a challenge for traditional solution methods.

To approach this problem, the {otherproduct1} uses a predictive model created with a https://en.wikipedia.org/wiki/Convolutional_neural_network[convolutional neural network (CNN)].
CNNs have been shown to achieve higher accuracy in detecting and segmenting specific objects in images.
In this solution, you use a https://vitalflux.com/cnn-basic-architecture-for-classification-segmentation/[CNN architecture] consisting of three convolutional layers and two dense layers with the https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be[RMSprop optimizer] and https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e[binary cross-entropy loss function].


CNNs must be trained before they can be useful.
CNN training can involve https://en.wikipedia.org/wiki/Unsupervised_learning[unsupervised learning] or https://en.wikipedia.org/wiki/Supervised_learning[supervised learning].
Unsupervised learning is indicated when the categories are unknown or when the training dataset is not already categorized (that is, labeled or tagged).
In this case, you have two categories already defined ('cancer' and 'not cancer') and a categorized training dataset.
So, the {otherproduct1} uses supervised learning to train its CNN.

The training process is detailed as follows:

. *Split the dataset*
//
+
https://machinelearningknowledge.ai/training-testing-validation-machine-learning/[Split the dataset] such that 80% is used for training, 10% is used for validation, and the remaining 10% is used for testing.
These images and their attached labels are saved to the `dataset` directory.
+
image::edge-analytics_healthcare_train_test_split.png[Dataset Split, scaledwidth="80%"]

. *Preprocess the data*
//
+
Convert the images to grayscale and resize to 512x512 pixels, and convert the labels to https://www.educative.io/blog/one-hot-encoding[one hot encoding].
Save preprocessed data to the `preprocessed` directory.
+
image::edge-analytics_healthcare_dataset_overview.png[Dataset Overview, scaledwidth="50%", align="center"]

. *Train the model*
//
+
Feed the training data (images and labels) to the CNN in batches of 32 and do this for 200 epochs.
When completed, save the trained model to the `trained-model` directory.
The validation data can be used to assess the performance of the model and determine whether further training is required.
+
//image::trained_grid.png[Model Architecture, scaledwidth="80%"]

image::edge-analytics_healthcare_prediction_cancer.png[Cancer Prediction, scaledwidth="80%", align="center"]

. *Use the model*
//
+
Copy the trained model to the `prediction-model` directory.
Feed a new image (from the test data) to the prediction model to receive a prediction.


No machine learning model is perfect.
It is quite common to retrain CNNs on new data, including updated labels for misclassified images.
The {otherproduct1} allows for retraining and automates the process with Kubeflow Pipelines.


== Deploy the applications

{otherproduct1} is built on top of https://flask.palletsprojects.com/[Flask], a lightweight Web application framework.
You can find the code under `application` inside your project directory, which you created earlier by cloning the project repository.
The solution contains two separate applications: one for the doctor (under `doctor_app`) and one the radiologist (under `lab_tech`).

[listing]
----
/application
-- doctor_app/
   -- app.py
   -- Dockerfile
   -- classification-model.h5
   -- prediction-model.h5
   -- requirements.txt
   -- static/
      -- styles/
         -- css/
         -- js/
   -- template/
      -- base.html
      -- gallery.html
      -- predict.html
      -- retrain.html
      -- upload.html

-- lab_tech/
   -- app.py
   -- Dockerfile
   -- classification-model.h5
   -- adjust.py
   -- requirements.txt
   -- static/
      -- styles/
         -- css/
         -- js/
   -- template/
      -- base.html
      -- predict.html
      -- send.html
      -- upload.html
----


=== Deploy and access the Lab Technician Interface

The Lab Technician Interface is responsible for getting DICOM image as input.
The person (radiologist, lab technician, physician) can read all the information associated with the DICOM image and alter information, such as _contrast_, _brightness_, or _angle of rotation_.

The Lab Technician Interface has a streamlined installation process using Kubernetes manifests.

. If you have not already done so, clone the application code repository.
+
[source, bash]
----
git clone https://github.com/abhi-bhatra/ct_image_scanning.git
----

. Change to the `ct_image_scanning/kubernetes-manifests/lab-tech` directory.
+
[source, bash]
----
cd ct_image_scanning/kubernetes-manifests/lab-tech
----

. Apply the kustomization file to deploy the Lab Technician Interface
+
[source, bash]
----
kubectl apply -k .
----


=== Deploy the Doctor's Dashboard

The Doctor's Dashboard lets a doctor access reports sent by a lab technician, along with the {otherproduct1}'s cancer prediction.

You can install the Doctor's Dashboard with the manifests included in the code repository that you cloned in the previous section.

. Change the directory to `ct_image_scanning/kubernetes-manifests/doctor-app/`

. Apply the kustomization file to deploy the Doctor's Dashboard Interface
+
[source, bash]
----
kubectl apply -k .
----


=== Verify installation

After you perform the above installations, validate that the {otherproduct1} is installed and running.

. List the pods running in the 'cancerns' namespace.
+
[source, bash]
----
kubectl get all --namespace cancerns
----
This should produce output like the following:
+
[source, bash]
----
NAME                               READY   STATUS    RESTARTS   AGE
pod/datasetvm-5db64d7549-cflmf     1/1     Running   0          9s
pod/doctor-app-d5b856997-64gnt     1/1     Running   0          10s
pod/labtech-app-6c54f58874-jdmcw   1/1     Running   0          12s

NAME                  TYPE       CLUSTER-IP    EXTERNAL-IP    PORT(S)          AGE
service/doctor-svc    NodePort   10.0.66.40    None           5002:30001/TCP   23s
service/labtech-svc   NodePort   10.0.145.57   None           5001:32009/TCP   24s

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/datasetvm     1/1     1            0           13s
deployment.apps/doctor-app    1/1     1            0           23s
deployment.apps/labtech-app   1/1     1            0           23s

NAME                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/datasetvm-5db64d7549     1         1         1       13s
replicaset.apps/doctor-app-d5b856997     1         1         1       10s
replicaset.apps/labtech-app-6c54f58874   1         1         1       21s
----

. Verify that you see `doctor-app-` and `labtech-app-` pods in the 'Running' state and the `service/doctor-svc` and `service/labtech-svc` are assigned CLUSTER-IP addresses.

. Connect to `labtech-svc` with your Web browser through the Rancher UI.

.. In the Rancher UI, select the application cluster, then click __Services__.

.. Click the displayed port number for the `labtech-svc` service to be redirected to the Lab Technician Interface.

. Repeat these steps to connect to the `doctor-svc` service through the Rancher UI.




=== Configure external access

The final step in configuring the {otherproduct1} is to enable external access.

With SUSE Rancher, you can configure https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/[load balancers] or https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/[ingress controllers] to redirect service requests.
Load balancers can only handle one IP address per service, while ingress works with one or more ingress controllers to dynamically route service requests.

For real-world use, it is recommended that you configure your cluster with an ingress.


[NOTE]
====
Ingress and ingress controllers residing in RKE-launched clusters are powered by https://www.nginx.com/[NGINX].
====

Below is a sample ingress resource for the {otherproduct1}:

[listing]
----
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-cancerprediction
spec:
  rules:
  - host: "cancerpred.example.com"
    http:
      paths:
      - path: /doctor
        pathType: Prefix
        backend:
          service:
            name: doctor-svc
            port:
              number: 443
      - path: /labtech
        pathType: Prefix
        backend:
          service:
            name: labtech-svc
            port:
              number: 443
----

[TIP]
====
You must have properly configured DNS resolution to use a domain name (such as 'cancerpred.example.com') for application access.
====


== Operational overview

The {otherproduct1} has two primary interfaces, the Lab Technician Interface and the Doctor's Dashboard.


=== Lab Technician Interface

. Open your Web browser to the Lab Technician Interface at 'https://HOSTADDRESS/labtech' (replace HOSTADDRESS with the domain name or IP address you specified in your ingress configuration).
+
[TIP]
====
You can still access the Lab Technician Interface through the Rancher UI as you did earlier.
====

. With the Lab Technician Interface, you can upload a new DICOM image.
+
image::edge-analytics_healthcare_labtech_1.png[Lab Tech Interface, scaledwidth="85%" align="center"]

. Adjust brightness and contrast, and then send a report.
+
image::edge-analytics_healthcare_labtech_2.png[Lab Tech Interface, scaledwidth="85%" align="center"]


=== Doctor's Dashboard

. Open your Web browser to the Doctor's Dashboard at 'https://HOSTADDRESS/doctor' (replace HOSTADDRESS with the address you defined in your ingress) or through the Rancher UI.

. From the Doctor's Dashboard, the doctor can see and select from available reports.
+
image::edge-analytics_healthcare_doctor_1.png[Doctor's Dashboard 1, scaledwidth="85%", align="center"]

. A report in the Doctor's Dashboard includes the image, the body part shown, and a cancer prediction.
+
image::edge-analytics_healthcare_doctor_2.png[Doctor's Dashboard 2, scaledwidth="85%", align="center"]

. If the doctor is not satisfied with the prediction, the doctor can send the DICOM image back to retrain the model.
+
image::edge-analytics_healthcare_doctor_3.png[Doctor's Dashboard 3, scaledwidth="85%", align="center"]



== Summary

Advanced analytics and machine learning are helping deliver better healthcare outcomes.
By leveraging SUSE Rancher and a Kubernetes-native approach, life-saving applications can be deployed everywhere - in the data center, in the cloud, and even at the edge.


Continue your learning journey:

* https://www.youtube.com/watch?v=Hy00J1eoQ1c[Google Summer of Code 2022 project demonstration]
* https://documentation.suse.com/trd/[SUSE Technical Reference Documentation]
* https://www.suse.com/community/[SUSE & Rancher Community]
* https://medium.com/@abhinavsharma332/deploying-wordpress-over-rancher-cb9539b1d7da[Getting Started with Sample workload over Rancher]
* https://medium.com/@abhinavsharma332/empowering-machine-learning-applications-on-rancher-f4e368a9009[Empowering Machine Learning Application on Rancher]
* https://medium.com/@abhinavsharma332/orchestrate-machine-learning-model-with-kubeflow-11945e7801b5[Orchestrate Machine Learning Model with Kubeflow]




// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Do not modify below this break.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

++++
<?pdfpagebreak?>
++++


:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
