:docinfo:
include::./common_docinfo_vars.adoc[]

// test
// Variables & Attributes
:title: Kasten K10 by Veeam with SUSE Rancher : Getting Started
:productname: SUSE Rancher 2.6
:partnerproductname: Kasten K10 by Veeam
:author1: Adam Bergh, Solutions Architect, Cloud Native Technical Partnerships, Kasten by Veeam
:author2: Gerson Guevara, IHV Solutions Architect, SUSE
:author3: Terry Smith, Global Partner Solutions Director, SUSE
//:revdate: March 08, 2022
//:revnumber: 20220308
//:toc2:
//:toc-title: {title}
//:toclevels: 4


= {title}



== Introduction

=== Motivation

// Why this would be of interest
// Challenges
// Benefits

Organizations are shifting to cloud native, leveraging containerized workloads and Kubernetes management platforms, like SUSE Rancher, to gain greater flexibility, scale, and resilience in order to accelerate innovation and quickly adjust to dynamic conditions.
In this always-on IT environment, application mobility, and data protection are critical considerations. 

image::logo-lockup_suse-rancher_veeam-kasten_hor_dark_new.svg[scaledwidth="75%", align="center"]


The Kasten K10 by Veeam® data management platform provides enterprise operations teams with an easy-to-use, scalable, and secure system for backup and restore, disaster recovery, and mobility of cloud native applications. 


=== Scope

// This guide will help you take the first steps to 
This guide provides an overview of the steps to install and set up Kasten K10 by Veeam in your SUSE Rancher Kubernetes environment and to perform a simple backup and restore of an application.


=== Audience

// This document is intended for 
This document is intended for IT operations teams, backup administrators, DevOps and DevSecOps teams, and others who are responsible for ensuring business continuity, disaster recovery, ransomware and threat reduction, and application migration for cloud native landscapes.



== Technical overview

// Description
The Kasten K10 by Veeam® data management platform has deep integrations with SUSE Rancher and has an extensive ecosystem of support across Kubernetes distributions and cloud platforms to provide enterprise operations teams flexibility to choose the deployment environments that best meet their needs - on-premises, public cloud, and hybrid.
K10 is policy-driven and extensible, delivering enterprise features, such as full-spectrum consistency, database integrations, automatic application discovery, multi-cloud mobility, and a powerful web-based user interface.

// Architecture diagram
image::rancher_veeam-kasten_architecture-1.png[scaledwidth="85%", align="center"]


== Prerequisites
// Minimum requirements (prerequisites) for this guide
// * Requirement 1 https://url[url]
// * Requirement 2 https://url[url]
For this guide, you will need the following:

* SUSE Rancher
+
See https://rancher.com/docs/rancher/v2.6/en/installation/requirements/[SUSE Rancher installation guide]

* Kubernetes cluster managed by SUSE Rancher
+
See https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/rancher-v2-6-3/[SUSE Rancher Support Matrix]

* Storage for backup target
+
An external backup storage target, such as an NFS file server or cloud object store.  This document will use an external, S3-compatible object storage bucket.

* User application to demonstrate back up and restore capability
+
For example, WordPress can be easily installed by https://bitnami.com/stack/wordpress/helm[Helm chart].


K10 can be installed in a variety of different environments.
To ensure a smooth installation experience, run the pre-flight checks to ensure that the prerequisites are met. 

Assuming that your default kubectl context is pointed to the cluster into which you want to install K10, you can run pre-flight checks by deploying the primer tool.
This tool runs in a pod in the cluster and does the following:

* Validates that the Kubernetes settings meet the K10 requirements. 

* Catalogs the available StorageClasses. 

* If a CSI provisioner exists, it will also perform a basic validation of the cluster's CSI capabilities and any relevant objects that may be required.
+
See https://docs.kasten.io/latest/install/storage.html#csi-preflight[CSI pre-flight checks] in the documentation for more details.


Run the following command to deploy the pre-check tool: 
[source, bash]
----
curl https://docs.kasten.io/tools/k10_primer.sh | bash
----

NOTE: This will create and clean up a ServiceAccount and ClusterRoleBinding to perform sanity checks on your Kubernetes cluster.



== Installing Kasten K10

Kasten K10 can be easily deployed from the SUSE Rancher __Apps & Marketplace__. 

. Create a new https://rancher.com/docs/rancher/v2.6/en/project-admin/namespaces/[namespace] for the Kasten K10 application. 

.. In the SUSE Rancher user interface (UI), navigate to __Clusters__ -> __Project/Namespaces__.
+
image::rancher_veeam-kasten_step1-1.png[scaledwidth="85%", align="center"]

.. Create a "kasten-io" namespace for Kasten K10.
+
image::rancher_veeam-kasten_step1-2.png[scaledwidth="85%", align="center"]

. Install Kasten K10.

.. Navigate to __Apps & Marketplace__ > __Charts__ within the SUSE Rancher UI and search for “Kasten.”
+
image::rancher_veeam-kasten_step2-1.png[scaledwidth="85%", align="center"]

.. Click the K10 chart and then click __Install__.
+
image::rancher_veeam-kasten_step2-2.png[scaledwidth="85%", align="center"]

.. Set the namespace to “kasten-io” and check the __Customize Helm Options__ box.
+
image::rancher_veeam-kasten_step2-3.png[scaledwidth="85%", align="center"]

.. Customize the Kasten K10 deployment, if needed.
The chart values screen, “Install: Step 2”, allows for customization of the Kasten K10 deployment.
This may be necessary, depending on the Kubernetes distribution into which you are installing.i
See the documentation for a detailed explanation of https://docs.kasten.io/latest/install/advanced.html#complete-list-of-k10-helm-options[available installation options].
After setting your chart values, click __Next__.
+
image::rancher_veeam-kasten_step2-4.png[scaledwidth="85%", align="center"]

.. Click __Install__ to install Kasten K10.
+
image::rancher_veeam-kasten_step3-1.png[scaledwidth="85%", align="center"]


. Validate the installation.
+
To validate that Kasten K10 has been properly installed, run the following command in K10's namespace ("kasten-io") and watch for the status of all K10 pods:
+
[source, bash]
----
kubectl get pods --namespace kasten-io --watch
----
+
It may take a couple of minutes for all pods to come up and display "Running" status.
+
[source, bash]
----
kubectl get pods --namespace kasten-io

NAMESPACE     NAME                                    READY   STATUS    RESTARTS   AGE
kasten-io     aggregatedapis-svc-b45d98bb5-w54pr      1/1     Running   0          1m26s
kasten-io     auth-svc-8549fc9c59-9c9fb               1/1     Running   0          1m26s
kasten-io     catalog-svc-f64666fdf-5t5tv             2/2     Running   0          1m26s
...
----

NOTE: In the unlikely scenario that pods that are stuck in any other state, please see the https://docs.kasten.io/latest/operating/support.html#support[support documentation] to debug further.


== Accessing the K10 dashboard

The Kasten K10 dashboard is not exposed externally by default.
To establish a connection, use the following kubectl command:

[source, bash]
----
kubectl --namespace kasten-io port-forward service/gateway 8080:8000
----

NOTE: If you installed Kasten K10 with a different release name than k10 (specified via the `--name` option in the install command), replace the last occurrence of "k10" in the above URL with the specified release name. The revised URL would look like `http://127.0.0.1:8080/<release-name>/#/`.


NOTE: If you are running on GKE and want to access the dashboard without local kubectl access, see https://docs.kasten.io/latest/access/gcp_details/gcp_console_dashboard.html[K10 Dashboard Directly From the Google Cloud Console].



https://docs.kasten.io/latest/access/authentication.html#id5[Direct access] to the K10 dashboard requires a properly configured authentication method to secure access.
Basic authentication and token authentication are discussed below.
For more information, see https://kubernetes.io/docs/reference/access-authn-authz/authentication/[Kubernetes authentication].


=== Basic authentication

https://docs.kasten.io/latest/access/authentication.html#id6[Basic] authentication allows you to protect access to the K10 dashboard with a user name and password.

To enable basic authentication, you will first need to generate https://httpd.apache.org/docs/2.4/programs/htpasswd.html[htpasswd] credentials by either using an http://www.htaccesstools.com/htpasswd-generator/[online tool] or via the htpasswd binary found on most systems.
Once generated, you need to supply the resulting string with the Helm install or upgrade command using the following flags:

[source, bash]
----
--set auth.basicAuth.enabled=true \
--set auth.basicAuth.htpasswd='example:$apr1$qrAVXu.v$Q8YVc50vtiS8KPmiyrkld0'
----

Alternatively, you can use an existing secret contained in a file created with htpasswd.
The secret must be in the K10 namespace.
This secret must be created with the key named auth and the value as the password generated using htpasswd in the data field of the secret.

[source, bash]
----
--set auth.basicAuth.enabled=true \
--set auth.basicAuth.secretName=my-basic-auth-secret
----


=== Token authentication

https://docs.kasten.io/latest/access/authentication.html#id7[Token] authentication is also supported.
Token authentication allows using any token that can be verified by the Kubernetes server.
For more information about token authentication, see:

* https://docs.kasten.io/latest/access/authentication.html#id8[Obtaining Tokens]
* https://kubernetes.io/docs/reference/access-authn-authz/authentication/#authentication-strategies[Authentication Strategies]

[]
. To enable token authentication, use the following flag as part of the initial Helm install or subsequent Helm upgrade command.
+
[source, bash]
----
--set auth.tokenAuth.enabled=true
----

. Once the dashboard is configured, you will be prompted to provide a bearer token that will be used when accessing the dashboard.
+
//kubernetes_gs_rancher_veeam-kasten_image_kasten_signin-1
image::rancher_veeam-kasten_kasten_signin-1.png[scaledwidth="50%", align="center"]


The most common token type that you can use is a service account bearer token.

. You can use kubectl to extract such a token from a service account that you know has the proper permissions.

.. Get the SA secret
+
[source, bash]
----
sa_secret=$(kubectl get serviceaccount my-kasten-sa -o jsonpath="{.secrets[0].name}" --namespace kasten-io)
----

.. Extract the token
+
[source, bash]
----
kubectl get secret $sa_secret --namespace kasten-io -ojsonpath="{.data.token}{'\n'}" | base64 --decode
----

. Alternatively, you can create a new service account from which to extract the token.
+
[source, bash]
----
kubectl create serviceaccount my-kasten-sa --namespace kasten-io
----
+
In this case, you will need to create a role binding or cluster role binding for the account to ensure that it has the appropriate permissions for K10.
To learn more about the necessary K10 permissions, see https://docs.kasten.io/latest/access/authorization.html#authz[Authorization].


=== Kasten K10 dashboard overview

The K10 dashboard is divided into several different sections, described below.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-1: Welcome
image::rancher_veeam-kasten_K10_Dashboard-1.png[scaledwidth="75%", align="center"]

TIP: A guided tour of the K10 dashboard is available when the K10 dashboard is accessed for the first time or via the dashboard option on the https://docs.kasten.io/latest/usage/overview.html#k10-settings[Settings] page.


==== System overview

The top of the K10 dashboard displays a list of applications (currently mapped to namespaces), any policies that might exist in the system, and a summary of the cluster's backup data footprint.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-2: system overview
image::rancher_veeam-kasten_K10_Dashboard-2.png[scaledwidth="85%", align="center"]

After filtering for applications that have stateful services (defined as containing a persistent volume), the above screen breaks down each section into three categories:

* Unmanaged: There are no protection policies that cover this object.
* Non-compliant: A policy applies to this object, but the actions associated with the policy are failing (such as due to underlying storage slowness, configuration problems, etc.) or the actions haven't been invoked yet.
* Compliant: Objects with policies and the policy SLAs are being respected.


==== Applications, namespaces, and workloads

The K10 platform equates namespaces to applications for ease of use and consistency with Kubernetes best practices, use of role-based authentication controls (RBAC), and to mirror the most common application deployment patterns.
However, as shown later, policies can be defined to operate on more than one namespace or only operate on a subset of an application residing in a single namespace.

Assuming you have already installed applications, clicking on the __Applications__ card on the dashboard will take you to the following view.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-3: applications details
image::rancher_veeam-kasten_K10_Dashboard-3.png[scaledwidth="85%", align="center"]

TIP: You can filter the view by clicking on the __Compliant__, __Non-Compliant__, or __Unmanaged__ buttons.


An application is made up of multiple Kubernetes resources and workloads, including deployments and stateful sets. 

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-4: app details
image::rancher_veeam-kasten_K10_Dashboard-4.png[scaledwidth="65%", align="center"]

// Why is this image be needed?
//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-5
//image::rancher_veeam-kasten_K10_Dashboard-5.png[scaledwidth="85%", align="center"]


K10 policies are used to automate your data management workflows.
In the main dashboard, you will find a section on how to manage policies next to the __Applications__ card.
Policies combine actions you want to take (such as making a snapshot), frequency or schedule for how often you want to perform the action, and selection criteria for the resources you want to manage.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-6: policies
image::rancher_veeam-kasten_K10_Dashboard-6.png[scaledwidth="85%", align="center"]

When you click the __Policies__ card, you will notice that no default policies are created at install time, but a policy can be either created from this page or from the application page shown earlier.


== Creating a location profile 

K10 can invoke protection operations, such as snapshots, within a cluster without requiring additional credentials, and this may be sufficient if K10 is running in the major public clouds and actions are limited to a single cluster.
However, in most production situations, such as performing real backups, enabling cross-cluster and cross-cloud application migration, and enabling disaster recovery
To enable these actions that span the lifetime of any one cluster, K10 needs to be configured with access to external object storage or external NFS file storage.
This is accomplished via the creation of location profiles.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-7: location profiles
image::rancher_veeam-kasten_K10_Dashboard-7.png[scaledwidth="65%", align="center"]


Profile creation can be accessed from the __Settings__ icon in the top-right corner of the dashboard or via the https://docs.kasten.io/latest/api/profiles.html#api-profile[CRD-based Profiles API].
Location profiles are used to create backups from snapshots, move applications and their data across clusters and potentially across different clouds, and to subsequently import these backups or exports into another cluster.
To create a location profile, click __New Profile__ on the profiles page.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-8: new profile
image::rancher_veeam-kasten_K10_Dashboard-8.png[scaledwidth="40%", align="center"]

When exporting to or importing from an object storage location, you are required to pick an object storage provider, a region for the bucket if being used in a public cloud, and the bucket name.
If a bucket with the given name does not exist, it will be created.

If an S3-compatible object storage system is used that is not hosted by one of the supported cloud providers, an S3 endpoint URL will need to be specified and optionally, SSL verification might need to be disabled.
Disabling SSL verification is only recommended for test setups.

NOTE: When certain cloud providers (like AWS or Microsoft Azure) are selected, provider-specific options (such as IAM Roles) will appear for configuration, if needed.


Once you click __Validate__ or __Save__, the config profile will be created and a profile similar to the following will appear:

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-9: location profiles
image::rancher_veeam-kasten_K10_Dashboard-9.png[scaledwidth="85%", align="center"]


== Creating a policy

Protecting an application with K10, is usually accomplished by creating a policy.
Understanding these three concepts is essential:

* Snapshots and Backups: These are data capture mechanisms.  You may require just one or both, depending on your environment and requirements.
* Scheduling: This is specification of application capture frequency and snapshot/backup retention objectives.
* Selection: This is identification of the applications protected by a policy.  Resource filtering can be used to restrict what is captured on a per-application basis.

This section demonstrates how to use these concepts in the context of a K10 policy to protect applications.

K10 defines an application as a collection of namespaced Kubernetes resources associated with a workload (such as ConfigMaps and Secrets), relevant non-namespaced resources used by the application (such as StorageClasses), Kubernetes workloads (including Deployments, StatefulSets, standalone pods, etc.), deployment and release information available from Helm v3, and all persistent storage resources (such as PersistentVolumeClaims and PersistentVolumes).

While you can always create a policy from scratch through the Policies page, the easiest way to define policies for unprotected applications is to click on the __Applications__ card on the main dashboard.
This will allow you to see all applications in your Kubernetes cluster.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-10: applications
image::rancher_veeam-kasten_K10_Dashboard-10.png[scaledwidth="85%", align="center"]


To protect any unmanaged application, simply click __Create New Policy__ to open the __New Policy__ dialog.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-11: policy - new policy
image::rancher_veeam-kasten_K10_Dashboard-11.png[scaledwidth="85%", align="center"]


=== Snapshots and backups

All policies center around the execution of actions.
You start by selecting the snapshot action with an optional backup (called an export).


*Snapshots*

Snapshots form the basis of persistent data capture in K10.
They are typically used in the context of disk volumes (PVC/PVs) used by the application but can also apply to application-level data capture (such as with https://docs.kasten.io/latest/kanister/kanister.html#kanister[Kanister]).

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-12: snapshots - new policy
image::rancher_veeam-kasten_K10_Dashboard-12.png[scaledwidth="55%", align="center"]

Snapshots, in most storage systems, are very efficient in terms of having a very low performance impact on the primary workload, requiring no downtime, supporting fast restore times, and implementing incremental data capture.

However, storage snapshots usually suffer from constraints such as having relatively low limits on the maximum number of snapshots per volume or per storage array.

Most importantly, snapshots are not always durable.
Catastrophic storage system failure will destroy your snapshots along with your primary data.
Further, in a number of storage systems, a snapshot's lifecycle is tied to the source volume.
So, if the volume is deleted, all related snapshots might automatically be garbage collected at the same time.
It is therefore highly recommended that you create backups of your application snapshots.

[NOTE]
====
A number of public cloud providers (including AWS, Azure, and Google Cloud) actually store snapshots in object storage, and they are retained independent of the lifecycle of the primary volume.
However, this is not true of all public clouds, and an independent backup would provide essential safety.
Please check with your cloud provider's documentation for more information.
====


*Backups*

Backups overcome the limitations of application and volume snapshots by converting them to an infrastructure-independent format, deduplicating, compressing, and encrypting them before they are stored in an external object store or NFS volume.

To convert your snapshots into backups, activate __Enable Backups via Snapshot Exports__ during policy creation.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-13: backups via exports
image::rancher_veeam-kasten_K10_Dashboard-13.png[scaledwidth="65%", align="center"]



=== Scheduling

There are four components to K10 scheduling:

* Action frequency: how frequently the primary snapshot action should be performed
* Export frequency: how often snapshots should be exported to backups
* Retention schedule: how snapshots and backups are rotated and retained
* Timing: when the primary snapshot action should be performed



*Action frequency*

Snapshots can be set to execute at an hourly, daily, weekly, monthly, or yearly frequency, or on demand.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-14: backup frequency
image::rancher_veeam-kasten_K10_Dashboard-14.png[scaledwidth="65%", align="center"]

By default, hourly snapshots execute at the top of the hour, while weekly, monthly, and yearly snapshots execute at midnight UTC.
You can also specify the time at which scheduled actions execute and sub-frequencies that execute multiple actions per frequency.
Sub-hourly actions can be useful when you are protecting mostly Kubernetes objects or small data sets.
See https://docs.kasten.io/latest/usage/protect.html#advanced-schedule-options[Advanced Schedule Options] for more information.

[WARNING]
====
Care should be taken not to stress the underlying storage infrastructure or running into storage API rate limits.
Further, sub-frequencies do also interact with retention (described below).
For example, retaining 24 hourly snapshots at 15-minute intervals would only retain 6 hours of snapshots.
====


*Export frequency*

When __Enable Backups via Snapshot Exports__ is enabled, snapshots are exported as backups.
By default, every snapshot is exported, but you can limit this to a subset by selecting a daily, weekly, monthly, or yearly export frequency.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-15: export frequency
image::rancher_veeam-kasten_K10_Dashboard-15.png[scaledwidth="75%", align="center"]



*Retention schedule*

A powerful scheduling feature in K10 is the ability to use a https://en.wikipedia.org/wiki/Backup_rotation_scheme#Grandfather-father-son [GFS retention scheme] for cost savings and compliance.
With this backup rotation scheme, hourly snapshots and backups are rotated on an hourly basis with one graduating to daily every day, daily snapshots and backups are rotated each day with one graduating to weekly, and so on.
It is possible to set the number of hourly, daily, weekly, monthly, and yearly copies that need to be retained, and K10 will take care of cleanup.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-16: snapshot retention
image::rancher_veeam-kasten_K10_Dashboard-16.png[scaledwidth="65%", align="center"]

NOTE: It is not possible to set a retention schedule for on demand policies.

By default, the backup retention schedule is the same as the snapshot retention schedule.  You can make these independent schedules, if needed.
This allows you to create policies where a limited number of snapshots are retained for fast recovery from accidental outages while a larger number of backups are stored for long-term recovery.
This separate retention schedule is also valuable when a limited number of snapshots are supported on the volume but a larger backup retention count is needed for compliance.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-17: export retention
image::rancher_veeam-kasten_K10_Dashboard-17.png[scaledwidth="65%", align="center"]

Snapshots and backups created by scheduled runs of a policy can be retained and omitted from the retention counts by adding a `k10.kasten.io/doNotRetire: "true"` label to the https://docs.kasten.io/latest/api/actions.html#api-run-action[RunAction] created for the policy run.


[NOTE]
====
The retention schedule for a policy does not apply to snapshots and backups produced by https://docs.kasten.io/latest/usage/protect.html#manual-policy-runs[manual policy runs].
And you will need to clean up any artifacts created by manual policy runs.
====


*Timing*

By default, actions set to hourly execute at the top of the hour and other action frequencies execute at midnight UTC.

Unhide __Advanced Options__ to select how many times actions are executed within the frequency interval. 
For example, if the action frequency is daily, you can specify the hour of the day and the minutes after the hour when the action is to start.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-18: action frequency
image::rancher_veeam-kasten_K10_Dashboard-18.png[scaledwidth="65%", align="center"]

You can also customize the retention schedule by selecting which snapshots and backups will graduate and be retained for longer periods.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-19: snapshot retention
image::rancher_veeam-kasten_K10_Dashboard-19.png[scaledwidth="75%", align="center"]


TIP: You can toggle whether to display and enter times in local time or UTC, but all times are converted to UTC and do not change for daylight savings time.



=== Application selection

In K10, you can specify which applications are bound to a policy by name or label.


*Selection by name*

The most straightforward way to apply a policy to an application in K10 is to use its name (derived from the name of the namespace).
You can even select multiple application names for the same policy.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-20: app selection
image::rancher_veeam-kasten_K10_Dashboard-20.png[scaledwidth="75%", align="center"]


If you need a policy to span similar applications, use the asterisk ('\*') wildcard.
For example, if you specify 'mysql-*', then K10 will match all applications whose names start with 'mysql-'.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-21: app selection by name
image::rancher_veeam-kasten_K10_Dashboard-21.png[scaledwidth="75%", align="center"]

[NOTE]
====
For policies that need to span all applications, use just the asterisk wildcard by itself.

// Hide image
//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-22 - App selection by Name - wildcard
//image::rancher_veeam-kasten_K10_Dashboard-22.png[scaledwidth="75%", align="center"]
====



*Selecting by label*

You can also use labels to bind a policy to multiple applications.
For example, you could protect all applications that use MongoDB or applications that have been annotated with, say, the 'gold' label.
Matching occurs on labels applied to namespaces, deployments, and statefulsets.
If multiple labels are selected, a union (logical OR) will be performed, matching all applications with at least one of the labels.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-24: app selection by label
image::rancher_veeam-kasten_K10_Dashboard-24.png[scaledwidth="75%", align="center"]


Label-based selection can be used to create forward-looking policies, as such policy would automatically apply to any future application with the matching label.
For example, if you use a label of 'heritage: Tiller' (for Helm v2) or 'heritage: Helm' (for Helm v3), the selector will apply the policy to any new Helm-deployed applications because the label is applied to any Kubernetes workload created by the Helm package manager.



[NOTE]
====
K10 can also protect cluster-scoped resources without targeting any applications.
To specify this, select __None__.
For more information about protecting cluster-scoped resources, see https://docs.kasten.io/latest/usage/clusterscoped.html#clusterscoped[Cluster-Scoped Resources].

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-23: custer-scoped
image::rancher_veeam-kasten_K10_Dashboard-23.png[scaledwidth="75%", align="center"]
====



== Working with policies

Once you have created a policy and have navigated back to the main dashboard, you will see the selected applications quickly switch from unmanaged to non-compliant.
That is, a policy covers the objects but no action has been taken yet.
The applications will switch to compliant as snapshots and backups are run and the application enters a protected state.
You can also scroll down the page to see the activity, how long each snapshot took, and the generated artifacts.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-25: activity
image::rancher_veeam-kasten_K10_Dashboard-25.png[scaledwidth="75%", align="center"]


NOTE: More detailed job information can be obtained by clicking on the in-progress or completed jobs.


=== Manual policy runs

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-26: manual policy
image::rancher_veeam-kasten_K10_Dashboard-26.png[scaledwidth="65%", align="center"]

It is possible to manually run a policy by clicking the __run once__ button on the desired policy.  Any artifacts created by this action will not be eligible for automatic retirement and will need to be manually cleaned up.


=== Restoring existing applications

Restoring an application is accomplished via the __Applications__ page.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-27: applications - restore
image::rancher_veeam-kasten_K10_Dashboard-27.png[scaledwidth="75%", align="center"]

[NOTE]
====
While the UI uses the "export" term for backups, no import policy is needed to restore from a backup.
Import policies are only needed when you want to restore the application into a different cluster.
====


To restore an application, simply click the __restore__ icon in the application's card. 

Next, you can select a restore point.
These are distinguished in the UI as having been generated manually or automatically through a backup policy.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-28: applications - restore point
image::rancher_veeam-kasten_K10_Dashboard-28.png[scaledwidth="75%", align="center"]

A restore point may include snapshots (native to the cluster) and backups (exported outside the cluster) with the same data.
When both snapshots and backups are present, as seen above, the UI provides you the option to select the instance you wish to use to restore the application.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-29: applications - restore - instance
image::rancher_veeam-kasten_K10_Dashboard-29.png[scaledwidth="75%", align="center"]


Selecting a restore point will bring up a side-panel containing more details on the restore point for you to preview before you initiate an application restore.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-30: applications - restore - instance - details
image::rancher_veeam-kasten_K10_Dashboard-30.png[scaledwidth="75%", align="center"]

Once you click __Restore__, the system automatically recreates the entire application stack into the selected namespace.
This not only includes data associated with the original application but also the versioned container images.


[NOTE]
====
Restored PersistentVolumes may not have the annotations specified in the original PersistentVolume.
====


After the restore completes, you are able to go back to your application and verify that the state was restored to what existed at the time the restore point was obtained.


=== Restoring deleted applications

The process to restore a deleted application is nearly identical.
The only difference is that removed applications are not shown on the Applications page by default.
To discover them, you simply need to filter and select __Removed__.

//kubernetes_gs_rancher_veeam-kasten_image_K10_Dashboard-31: applications - filter removed
image::rancher_veeam-kasten_K10_Dashboard-31.png[scaledwidth="75%", align="center"]

Once the filter is in effect, you see applications that K10 has previously protected but no longer exist.
These can now be restored using the normal restore workflow.


== Summary

//Summarize the motivation
//Summarize what was demonstrated
//Hint at other capabilities.

SUSE Rancher enables enterprises to streamline multi-cluster Kubernetes operations everywhere with unified security, policy, and user management.  Kasten K10 by Veeam delivers easy-to-use, Kubernetes native application backup and restore, disaster recovery, and application mobility.  Together, SUSE and Veeam give enterprises the tools they need to reduce risk and accelerate cloud native success.

In this guide, you learned how to seamlessly deploy Kasten K10 into your Rancher Kubernetes landscape, create policy-driven backups, and restore applications.


Continue your journey with these additional resources:
//Use an unordred lists for references

* https://youtu.be/c_mSNy6Q9RU["Cloud native workload protection with Kasten K10 by Veeam and SUSE Rancher" - demonstration video]
* https://www.suse.com/c/kasten-k10-by-veeam-and-suse-rancher-enterprise-k8s-data-protection/["Kasten K10 by Veeam and SUSE Rancher: Enterprise K8s data protection" - blog article]
* https://www.suse.com/c/deploying-multicluster-day-2-operations-with-suse-rancher-fleet-and-kasten-k10/["Deploying Multicluster Day 2 Operations with SUSE Rancher, Fleet, and Kasten K10" - blog article]
* https://www.suse.com/products/suse-rancher/get-started/[Get started with SUSE Rancher in 2 easy steps]
* https://www.kasten.io/free-kubernetes[Download Kasten K10 for free and use it for up to 5 nodes]
* https://docs.kasten.io/latest/index.html[Kasten K10 Documentation]
* https://rancher.com/docs/rancher/v2.x/en/[Rancher Documentation]




++++
<?pdfpagebreak?>
++++

// Standard SUSE Technical Reference Documents includes

:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
