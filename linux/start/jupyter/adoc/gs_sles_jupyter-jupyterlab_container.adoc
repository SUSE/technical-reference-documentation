:docinfo:
include::./common_docinfo_vars.adoc[]

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// General comments
// Keep in mind that this is a "getting started" guide and the
//   audience that we are trying to reach.
// Leverage ASCIIDoc features to make this document readable and usable:
//   - Text highlights (follow SUSE style guides)
//   - Admonitions (i.e., NOTE, TIP, IMPORTANT, CAUTION, WARNING)
//   - Code blocks
//   - Lists (ordered and unordered, as appropriate)
//   - Links
//   - Images
//     - Place image files under the ./media directory tree
//       (e.g., ./media/src/svg, ./media/src/png)
//     - Format preferences: svg > png > jpg
//     - Consolidate images wherever possible;
//       that is, prefer text over images
//   - Sections and subsections to organize content and break up actions
// 
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =


// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Variables & Attributes
// Follow indicated patterns.
//   E.g., "Ondat data plane with SUSE Rancher"
//         "Grace Hopper, Engineer, US Navy"
//         "SUSE Linux Enterprise Server 15 SP4"
//         "SUSE Rancher 2.6"
// NOTE: Some variables & attributes have been deprecated and
//       have been commented out below.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

:title: Python and JupyterLab with SUSE Linux Enterprise Base Container Images: Getting Started
:productname: SLE BCI 15 SP4
:defaultpython: Python 3.10
:partnerprod1: JupyterLab
:author1: Brian Fromme, Alliance Solution Architect, SUSE
:author2: Terry Smith, Partner Solutions Director, SUSE
:revdate: Month dd, YYYY
:revnumber: YYYYmmdd
//:toc2:
//:toc-title: {title}
//:toclevels: 4


= {title}



== Introduction

=== Motivation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// In this section, provide motivation for the document.
// Provide a brief statement (2-4 sentences) to identify
//   - what products are being highlighted
//   - what the document is about and why it may be of
//     interest to the reader and beyond.
// Include an approved SUSE | Partner logo lock-up
// Include additional details if needed, like
//    - the challenges that are or can be addressed
//    - specific benefits of this solution
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

Modern software development is largely agile, open, and collaborative, resulting in:
A wealth of open source, optimized libraries, toolkits, and frameworks that are leveraged to support complex applications.
A rapid state of continuous development, delivering new value but also driving the need for CI/CD pipelines.

An essential need to share code efficiently and consistently.
Nowhere has this been more obvious than in the domain of machine learning (ML).
An explosion of ML advancement has driven the creation of tools and capabilities to support this agile, open, and collaborative development technology.

ML developers push hardware and software limits to achieve the performance and scale required to build and deploy models.
ML applications leverage low-level mathematics libraries developed for high-performance computing, as well as many higher-level libraries, toolkits, and frameworks to create models that help solve seemingly intractable problems.

Keras has become one of the most used deep learning frameworks among ML developers for its ease of use and performance.
Keras is built on TensorFlow 2 and can scale from a single system to a cluster of TPUs (tensor processing units).
TensorFlow 2 itself is an end-to-end, open source machine learning platform that supports multidimensional array (tensor) based numeric computation, GPU and distributed processing, model construction, training, and exporting.

Keras and TensorFlow 2 are part of a tightly-connected ecosystem, covering every step of the machine learning workflow, from data management to hyperparameter training to deployment of solutions.



=== Scope

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Specify what this guide covers in no more than 2 sentences.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This guide will help you take the first steps to building containers using SUSE technologies.
You will explore a machine learning example to get hands-on experience with containers.


=== Audience

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify for whom this document is intended, perhaps with:
//   - Topics of interests
//   - Potential job roles
//   - Required skills <- This can be critically important
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This document is intended for people working with machine learning for digital transformation and more.
Technology managers, system architects, software developers and data scientists will learn how to work with ML on SUSE technologies.


=== Prerequisites

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify minimum requirements (prerequisites) the reader
//   would need to have to follow the steps of this guide.
// Link to existing resources whenever possible
//   but don't be afraid to elaborate as needed.
// * Requirement 1 https://url[linktext]
// * Requirement 2 https://url[linktext]
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

NOTE: Define at a high level what is needed early, before the reader goes on



== Technical overview

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a technical overview of the solution.
// Identify components.
// Describe how the components fit together.
// Leverage diagrams as appropriate, including (but not limited to):
//   - component architecture
//   - data flow
//   - workflow
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

=== Python ML with Keras and TensorFlow 2

The goal of machine learning toolkits such as TensorFlow and Keras is to make simplify development by implementing and hiding complex low-level programming tasks.
Combined with the Python programming language, machine learning in Keras and TensorFlow allows data scientists to focus on the model and data transformations.
Data scientists and programmers must study Keras and TensorFlow libraries to understand how to implement these capabilities.

Once coding begins, the tools should be transparent and easy to manage in development, test, and production.
There are different approaches to managing these AI toolkits.
One approach is to define the versions that are required and stick with those on all platforms.
This approach requires error-prone effort across potentially many systems when new versions are chosen.
Another approach is to put all the AI toolkit and other library dependencies into a container, along with the application and its model.

=== Containers for Machine Learning Development

Containers put application artifacts and dependencies into an image that can easily be deployed on runtime environments in the cloud, at the edge, in data centers, or in testing.
By adding ML library dependencies to a container, you resolve challenges that occur when other machines don’t have the same libraries available.
The container removes the need to reference specific library versions on other machines.
Deploying library dependencies together with a machine-learning application simplifies the deployment workflow.
This guide will show an example of building a container for an ML program.

=== SLE Base Container Images

SUSE Linux Enterprise (SLE) Base Container Images (BCI) are starting points for supported operating system code from SUSE.
The SLE BCIs are freely available, re-distributable, and supported across many different environments.
SLE BCIs are open, flexible, and secure container images and application development tools, that leverage SUSE Linux Enterprise.
These images are designed to be a secure base for any containerized workload and are great for machine learning deployments.
Together with SUSE Edge technologies, SLE BCIs are used to quickly deploy ML applications on edge devices.

SLE BCI technology provides an enterprise better security and quality of their delivered applications and services.
By using SUSE-tested and support code, you can rely on the enhanced security that SUSE has invested in.
Your code will have higher-quality because you have based it on well-tested technologies, backed by a leading Linux vendor.

=== Python ML with Keras and TensorFlow 2

Now it’s time to work with a machine-learning example.
This guide uses the MNIST example, which is something of a standard for getting started with machine-learning code and concepts.
The MNIST example does analysis of hand-written digits between 0-9.
The code is well defined and documented for this problem both online and via books such as, “Deep Learning with Python.” [cite: Manning].
MNIST has a relatively small set of training images that can easily be downloaded and analyzed on a laptop or desktop computer.
And, MNIST does not require expensive GPUs for hardware acceleration of the training process.


== AI Toolkits: Installation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Detail the installation steps in an ordered list.
// The reader should be able to copy and paste commands
// to a local environment or follow along with screenshots.
//
// If multiple installation methods are discussed,
// create a list here, then detail each method in a subsection.
//
// NOTE: For solutions involving SUSE Rancher, it is preferred
//       to include installation through the Rancher Apps & Marketplace
//       with appropriate screenshots that show SUSE branding
//       as well as link to or detail a command-line method.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

// python3 -m venv $HOME/py-keras
// source $HOME/py-keras/bin/activate
// pip install --upgrade pip
// echo "Now do: pip install tensorflow"

Now you are ready to build up your AI toolkit environment.
This will lead you to building the MNIST example in a container.
Let's get started!

. Work in a Python virtual environment
+
[source, bash]
----
python3 -m venv $HOME/py-keras
source $HOME/py-keras/bin/activate
pip install --upgrade pip
----
+
The 'activate' script cannot be run on its own, but runs in your current shell environment.

Next you will load in the AI toolkits that are used from the MNIST example.

. Load TensorFlow and Keras Toolkits for MNIST example
+
[source, bash]
----
pip install tensorflow
----
+

TIP: TensorFlow already contains the Keras libraries used in the MNIST example model.

If you are not familiar with Keras, here is an
https://keras.io/getting_started/intro_to_keras_for_engineers/[introduction for engineers].

Now you can explore the MNIST example model and associated code.
A nice overview of how this example works is provided
https://keras.io/examples/vision/mnist_convnet/[here].

The MNIST data is already transformed into NumPy tensors for you as part of the Keras toolkit examples.

Now that you understand the model to be shown, the next step is to build this into a container.

== MNIST Model in a SLE BCI Container

There are two options to make a container with the code for the MNIST model.
The production option would be to build a web-based API to this code and put that in a container.
A development approach would be to work with this model in JupyterLab.
This guide will take the development approach.

SUSE created a getting started guide for JuptyerLab.
You can find that document, which is named _JupyterLab with SUSE Linux Enterprise Server: Getting Started_.
Please refer to that guide for more details on working with JupyterLab on SLES.

Here you will install JupyterLab in the current Python virtual environment.
Then you will load the MNIST code into a new notebook.

TIP:  Remember to return to your activated Python env, which this guide called _py-keras_.

. Install JupyterLab in your Python virtual environment
+
[source, bash]
----
pip install jupyterlab
----
+

. Download MNIST code to a new directory in your Python virtual environment
+
[source, bash]
----
cd ~/py-keras
mkdir mnist
cd mnist
curl -o mnist_convnet.py https://raw.githubusercontent.com/keras-team/keras-io/master/examples/vision/mnist_convnet.py
----
+

Now you can examine the MNIST code in JupyterLab.
Since you are current in the mnist directory, running JupyterLab there will make it easy to find the code.

. Run JupyterLab to view MNIST code
+
[source, bash]
----
jupyter-lab
----
+

TIP:  Grab the URL generated by the _jupyter-lab_ command and paste that into your browser.  Double-click _mnist_convnet.py_ to see the code.

There is a lot you can do at this point to experiment with the MNIST code.
Since the goal of this guide is to get this work into a container, that will be the next step.

When you are done experimenting with MNIST code, quit _jupyter-lab_ by entering a _Ctrl-C_ in the shell running that command.

=== Podman Overview

To build a container, you create a set of instructions that are handled by a container engine.
In SUSE Linux Enterprise, an excellent container engine choice is _Podman_.

Podman is short for Pod Manager Tool.
It is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers on a Linux system.
Podman offers a drop-in alternative for Docker and is the default container runtime in openSUSE Kubic — a certified Kubernetes distribution built on top of openSUSE.

You can read more about Podman from the 
https://docs.podman.io/en/latest/[Podman online documentation].

You can also learn more from the
https://documentation.suse.com/sles/15-SP4/single-html/SLES-container/index.html[SUSE Container Guide].

You will use Podman to create a container of the JupyterLab environment you have built.
You can easily move that container to other machines to be run by a container runtime, or run the container locally.


=== Installing Podman

To use Podman for your container creation, you will need to install it.
First, you need to enable the SUSE reposity for the Containers Module.

. Enable repo for the SUSE Containers Module
+
[source, bash]
----
sudo SUSEConnect -p sle-module-containers/15.4/x86_64
----
+

TIP: The Containers Module is a free add-on module for your SUSE Linux Enterprise Server system.

With the Containers Module enabled, you can now install Podman.

. Install Podman
+
[source, bash]
----
sudo zypper in podman
----
+
TIP:  Sometimes you might also want to update your machine before installing new software.

=== Create the Containerfile

A _Containerfile_ is a set of instructions that tell the container engine how to build your container.
If you are familiar with Docker, a Containerfile has the same format as a Dockerfile.
You can read more about Containerfiles here:
* https://docs.podman.io/en/latest/markdown/podman-build.1.html
* https://github.com/containers/common/blob/main/docs/Containerfile.5.md

Before you construct the Containerfile for the JupyterLab container, here's a useful tip about container user environments.

==== Linux User Environments in Containers

One reason that IT organizations prefer Podman is that it can run containers with requiring root access.
As you can imagine, having root access on the machines that run containers is a huge security hole.
In short, most IT organization will not allow root access on production environments.

Podman can run containers without requiring root access.
One way it does this is by using a Linux kernel feature called namespaces, which is widely used in container technologies.
User environments inside a namespace can be grouped and segmented away from the defaul user IDs.
This means your container will run as a different user ID on a target machine than your development user ID.
This is a great feature, but something we may want to change in a development scenario.

==== A Container Method to Map a User ID

The following example shows you how to map your current user ID to that of the running container.
This example uses the ENTRYPOINT feature of a Containerfile to leverage a script that passes your local user ID to the container.

The entrypoint script creates a username inside the container and use an environment variable to set the container's UID to that of the user executing the *podman run* command.

. Bash ENTRYPOINT script
+
[source, bash]
----
#!/bin/bash

# DEBUG: optional debug verbosity
[[ $DEBUG -eq 1 ]] && set -x

# add container user, passed LOCAL_USERID required
CONT_UID=${LOCAL_USERID:?}
CONT_UNAME=jupyterlab
CONT_HOME=/home/${CONT_UNAME}
VIRTENV=/home/virtenv

echo "Starting with UID : $CONT_UID"
groupadd mail
useradd -s /bin/bash -u $CONT_UID -d $CONT_HOME -m $CONT_UNAME

# useradd will not apply skel files if the container homedir is created
# via a container engine's --mount flag, so force the copy of these files.
cp -ar /etc/skel/. ${CONT_HOME}/
chown -R $CONT_UID $CONT_HOME

# DEBUG: allow user to edit virtenv
[[ $DEBUG -eq 1 ]] && chown -R $CONT_UID $VIRTENV

# place container engine CMD into a script to facilitate an exec
echo "$@" > /usr/local/bin/cmd.sh
chmod +x /usr/local/bin/cmd.sh

# exec CMD as the local user
exec su - $CONT_UNAME -c /usr/local/bin/cmd.sh
----
+

A quick summary of what is happening in this script is important.
It is not important that you understand all the details of this script, unless it is interesting to you.

NOTE:  TBD.  Describe how the LOCAL_USERID variable is extracted and used in the container.


. Containerfile Using the ENTRYPOINT script
+
[source, bash]
----
# https://registry.suse.com/
FROM registry.suse.com/bci/bci-base:latest

ENV ZYPPERCMD="zypper --non-interactive"

RUN $ZYPPERCMD install python3 python3-pip
RUN python3 -m venv /home/virtenv

COPY requirements.txt .
RUN . /home/virtenv/bin/activate && pip install --upgrade pip
RUN . /home/virtenv/bin/activate && pip install -r requirements.txt

# jupyter web port
EXPOSE 8888/tcp

# https://denibertovic.com/posts/handling-permissions-with-docker-volumes/
COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN chmod +x /usr/local/bin/entrypoint.sh
ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
CMD [".", "/home/virtenv/bin/activate", "&&", "jupyter", "lab"]
----
+

Let's spend some time with the pieces of this Containerfile

NOTE:  TBD.  Describe how this Containerfile works


// Run
// 
// The entrypoint script will create the username jupyter inside the container
// and use $LOCAL_USERID to align the container's jupyter UID with the UID of
// the user executing the podman run command.
// 
// JupyterLab is then launched from the virtual environment in
// /home/virtenv with the start directory of /home/jupyter.
// 
// Environment Variables
// - LOCAL_USERID is required and should match the local UID
// - DEBUG=1 is optional, enables verbosity and editing of virtenv
// 
// 
// mkdir -p jupyterlab
// sudo podman run \
// --mount type=bind,source="$(pwd)/jupyterlab",target=/home/jupyterlab \
// --network host \
// --env LOCAL_USERID=$UID \
// --env DEBUG=0 \
// localhost/jupyterlab



=== Build the Container

TBD: tbd

=== Run the Container

TBD: tbd

=== Test the Container

TBD: tbd



== Demonstration

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Describe use case / functionality to be demonstrated, followed by
//   the demonstration itself.
// Typical demonstration flow is:
//   1. Prepare (environment for demonstration)
//   2. Perform (actions of demonstration)
//   3. Verify (demonstration worked)
// Depending on the size and complexity of each step,
//   the demonstration can be broken into subsections.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =




== Summary

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Summarize what was covered, including:
//   - Motivation
//   - Installation
//   - Demonstration
// Include any hints about other capabilities.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =




== Additional resources

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide any additional resources that may help the reader
//   continue to explore this topic.
// Use an unordered list for references.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =





// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Do not modify below this break.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

++++
<?pdfpagebreak?>
++++


:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
