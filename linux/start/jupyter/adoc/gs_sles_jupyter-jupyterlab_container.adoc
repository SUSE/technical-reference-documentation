:docinfo:
include::./common_docinfo_vars.adoc[]

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Variables & Attributes
// Follow indicated patterns.
//   E.g., "Ondat data plane with SUSE Rancher"
//         "Grace Hopper, Engineer, US Navy"
//         "SUSE Linux Enterprise Server 15 SP4"
//         "SUSE Rancher 2.6"
// NOTE: Some variables & attributes have been deprecated and
//       have been commented out below.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

:title: Python and JupyterLab with Podman and SUSE Linux Enterprise Base Container Images: Getting Started
:productname: SLE BCI 15 SP4
:defaultpython: Python 3.10
:partnerprod1: JupyterLab
:author1: Brian Fromme, Alliance Solution Architect, SUSE
:author2: Terry Smith, Partner Solutions Director, SUSE

= {title}



== Introduction

=== Motivation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// In this section, provide motivation for the document.
// Provide a brief statement (2-4 sentences) to identify
//   - what products are being highlighted
//   - what the document is about and why it may be of
//     interest to the reader and beyond.
// Include an approved SUSE | Partner logo lock-up
// Include additional details if needed, like
//    - the challenges that are or can be addressed
//    - specific benefits of this solution
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

Modern software development is largely agile, open, and collaborative.
Nowhere has this been more obvious than in the domain of machine learning (ML).
The resulting explosion of ML advancement has driven:

* A wealth of open source, optimized libraries, toolkits, and frameworks that are leveraged to support complex applications.

* A rapid state of continuous development, delivering new value and highlighting the need for automation and CI/CD pipelines.

* An essential need to share code efficiently and consistently.


ML developers create models that push the limits of hardware and software to achieve the performance and scale required to help solve seemingly intractable problems in record time.

TensorFlow 2 and Keras are popular with ML developers for creating production-grade models.
TensorFlow 2 is an end-to-end, open source ML platform that supports multidimensional array (tensor) based numeric computation, GPU and distributed processing, model construction, training, and exporting.
Keras is a high-level neural network API that simplifies the creation of complex deep learning (DL) models.
Keras is written in Python and is capable of running on top of TensorFlow 2 as well as other ML frameworks.
Keras and TensorFlow 2 form a tightly-connected ecosystem, covering every step of the ML worklfow - from data management to hyperparameter training to deployment - and can scale from a single system to a cluster of TPUs (tensor processing units).
This has made Keras and TensorFlow 2 among the most popular of ML frameworks.



=== Scope

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Specify what this guide covers in no more than 2 sentences.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This document illustrates how to take the your first steps in building containers with SUSE technologies to support ML development and implementation.
You get hands-on experience creating a container with an interactive, JupyterLab environment and a Keras and TensorFlow 2 ML model.


=== Audience

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify for whom this document is intended, perhaps with:
//   - Topics of interests
//   - Potential job roles
//   - Required skills <- This can be critically important
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

This document is intended for people working with ML and interested in getting started with container technologies.
Data scientists, ML developers, operations teams, systems architects and others can gain an appreciation for modern, cloud native software development and how this supports advanced analytics and ML.
To progress with this document, the reader should have general knowledge of container technologies and basic Linux command line skills.


=== Prerequisites

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Identify minimum requirements (prerequisites) the reader
//   would need to have to follow the steps of this guide.
// Link to existing resources whenever possible
//   but don't be afraid to elaborate as needed.
// * Requirement 1 https://url[linktext]
// * Requirement 2 https://url[linktext]
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

NOTE: Define at a high level what is needed early, before the reader goes on - this should focus on defining the minimum environment in which the reader can perform the tasks outlined in this guide.


=== Components and tools

Software components discussed in this guide are:

Keras:: Keras is an open-source software library that provides a Python interface for designing artificial neural networks. It acts as an interface for TensorFlow library. We are using keras to design https://www.tensorflow.org/tutorials/images/cnn[Convolutional Neural Nets (CNNs)] for our application.

Kubeflow:: Kubeflow is used for defining ML pipelines and to orchestrate workflows running on Kubernetes clusters.
Kubeflow  to focus on writing ML algorithms instead of managing their operations.


Some additional components and tools discussed in this guide include:

* https://rancher.com/[Rancher]: the Kubernetes management platform.

* https://kubernetes.io/[Kubernetes]:: Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation.

* https://podman.io/[Podman]: the container runtime used to build and run the application.

* https://documentation.suse.com/container/all/single-html/SLES-container/[SUSE Container Guide]: how to use and build containers on SLE systems.

== Technical overview

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide a technical overview of the solution.
// Identify components.
// Describe how the components fit together.
// Leverage diagrams as appropriate, including (but not limited to):
//   - component architecture
//   - data flow
//   - workflow
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

NOTE: See Abhinav's use of the Asciidoc definition style (Python::) to define/highlight components.

=== Python ML with Keras and TensorFlow 2

The goal of ML frameworks and toolkits, such as TensorFlow 2 and Keras, is to simplify development by implementing a high-level, API approach that hides complex low-level programming tasks.
Combined with the Python programming language, machine learning in Keras and TensorFlow allows data scientists to focus on the model and data transformations.
Data scientists and programmers must study Keras and TensorFlow libraries to understand how to implement these capabilities.

Once coding begins, the tools should be transparent and easy to manage in development, test, and production.
There are different approaches to managing these AI toolkits.
One approach is to define the versions that are required and stick with those on all platforms.
This approach requires error-prone effort across potentially many systems when new versions are chosen.
Another approach is to put all the AI toolkit and other library dependencies into a container, along with the application and its model.

=== Containers for Machine Learning Development

Containers put application artifacts and dependencies into an image that can easily be deployed on runtime environments in the cloud, at the edge, in data centers, or in testing.
By adding ML library dependencies to a container, you resolve challenges that occur when other machines don’t have the same libraries available.
The container removes the need to reference specific library versions on other machines.
Deploying library dependencies together with a machine-learning application simplifies the deployment workflow.
This guide will show an example of building a container for an ML program.

=== SLE Base Container Images

SUSE Linux Enterprise (SLE) Base Container Images (BCI) are starting points for supported operating system code from SUSE.
The SLE BCIs are freely available, re-distributable, and supported across many different environments.
SLE BCIs are open, flexible, and secure container images and application development tools, that leverage SUSE Linux Enterprise.
These images are designed to be a secure base for any containerized workload and are great for machine learning deployments.
Together with SUSE Edge technologies, SLE BCIs are used to quickly deploy ML applications on edge devices.

SLE BCI technology provides an enterprise better security and quality of their delivered applications and services.
By using SUSE-tested and support code, you can rely on the enhanced security that SUSE has invested in.
Your code will have higher-quality because you have based it on well-tested technologies, backed by a leading Linux vendor.

=== Python ML with Keras and TensorFlow 2

Now it’s time to work with a machine-learning example.
This guide uses the MNIST example, which is something of a standard for getting started with machine-learning code and concepts.
The MNIST example does analysis of hand-written digits between 0-9.
The code is well defined and documented for this problem both online and via books such as, “Deep Learning with Python.” [cite: Manning].
MNIST has a relatively small set of training images that can easily be downloaded and analyzed on a laptop or desktop computer.
And, MNIST does not require expensive GPUs for hardware acceleration of the training process.


== AI Toolkits: Installation

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Detail the installation steps in an ordered list.
// The reader should be able to copy and paste commands
// to a local environment or follow along with screenshots.
//
// If multiple installation methods are discussed,
// create a list here, then detail each method in a subsection.
//
// NOTE: For solutions involving SUSE Rancher, it is preferred
//       to include installation through the Rancher Apps & Marketplace
//       with appropriate screenshots that show SUSE branding
//       as well as link to or detail a command-line method.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

[NOTE]
====
In this guide, you focus on containerizing your Python-based ML development environment or application.
See https://documentation.suse.com/trd/linux/single-html/gs_sles_jupyter-jupyterlab/[Replicable Python Environments with JupyterLab and SUSE Linux Enterprise Server] to learn more about working with Python directly on your Linux desktop, in a VM, or on a remote server. 
====


// python3 -m venv $HOME/py-keras
// source $HOME/py-keras/bin/activate
// pip install --upgrade pip
// echo "Now do: pip install tensorflow"

Now you are ready to build up your AI toolkit environment.
This will lead you to building the MNIST example in a container.
Let's get started!

First, you need to create a Python virtual environment with tensorflow.
If you need help with these steps, see https://documentation.suse.com/trd/linux/single-html/gs_sles_jupyter-jupyterlab/[Replicable Python Environments with JupyterLab and SUSE Linux Enterprise Server].

// Terry, I put this snippet back, as I have a download section later that relies on some local directory, so I felt I should name it first.
To provide consistency across this document, below are steps that are typically used to create the virtual environment.
In particular, keep track of the name of the environment you create, as that will be a directory where you will download the MNIST code.

. Work in a Python virtual environment
+
[source, bash]
----
python3 -m venv $HOME/py-keras
source $HOME/py-keras/bin/activate
pip install --upgrade pip
pip install tensorflow
----
+
TIP: TensorFlow already contains the Keras libraries used in the MNIST example model.

If you are not familiar with Keras, here is an
https://keras.io/getting_started/intro_to_keras_for_engineers/[introduction for engineers].

Now you can explore the MNIST example model and associated code.
A nice overview of how this example works is provided
https://keras.io/examples/vision/mnist_convnet/[here].

The MNIST data is already transformed into NumPy tensors for you as part of the Keras toolkit examples.

Now that you understand the model to be shown, the next step is to build this into a container.

== MNIST Model in a SLE BCI Container

There are two options to make a container with the code for the MNIST model.
The production option would be to build a web-based API to this code and put that in a container.
A development approach would be to work with this model in JupyterLab.
This guide will take the development approach.

SUSE created a getting started guide for JuptyerLab.
You can find that document, which is named _JupyterLab with SUSE Linux Enterprise Server: Getting Started_.
Please refer to that guide for more details on working with JupyterLab on SLES.

Here you will install JupyterLab in the current Python virtual environment.
Then you will load the MNIST code into a new notebook.

TIP:  Remember to return to your activated Python environment before running the next steps.

. Install JupyterLab in your Python virtual environment
+
[source, bash]
----
pip install jupyterlab
----
+

. Download MNIST code to a new directory in your Python virtual environment
+
[source, bash]
----
cd ~/py-keras
mkdir mnist
cd mnist
curl -o mnist_convnet.py https://raw.githubusercontent.com/keras-team/keras-io/master/examples/vision/mnist_convnet.py
----
+

Now you can examine the MNIST code in JupyterLab.
Since you are current in the mnist directory, running JupyterLab there will make it easy to find the code.

. Run JupyterLab to view MNIST code
+
[source, bash]
----
jupyter-lab
----
+
TIP:  Grab the URL generated by the _jupyter-lab_ command and paste that into your browser.  Double-click _mnist_convnet.py_ to see the code.

There is a lot you can do at this point to experiment with the MNIST code.
Since the goal of this guide is to get this work into a container, that will be the next step.

When you are done experimenting with MNIST code, quit _jupyter-lab_ by entering a _Ctrl-C_ in the shell running that command.

=== Podman Overview

To build a container, you create a set of instructions that are handled by a container engine.
In SUSE Linux Enterprise, an excellent container engine choice is _Podman_.

Podman is short for Pod Manager Tool.
It is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers on a Linux system.
Podman offers a drop-in alternative for Docker and is the default container runtime in openSUSE Kubic — a certified Kubernetes distribution built on top of openSUSE.

You can read more about Podman from the 
https://docs.podman.io/en/latest/[Podman online documentation].

You can also learn more from the
https://documentation.suse.com/container/all/single-html/SLES-container/[SUSE Container Guide].

You will use Podman to create a container of the JupyterLab environment you have built.
You can easily move that container to other machines to be run by a container runtime, or run the container locally.


=== Installing Podman

To use Podman for your container creation, you will need to install it.
First, you need to enable the SUSE reposity for the Containers Module.

. Enable repo for the SUSE Containers Module
+
[source, bash]
----
sudo SUSEConnect -p sle-module-containers/15.4/x86_64
----
+
TIP: The Containers Module is a free add-on module for your SUSE Linux Enterprise Server system.

With the Containers Module enabled, you can now install Podman.

. Install Podman
+
[source, bash]
----
sudo zypper in podman
----
+
TIP:  Sometimes you might also want to update your machine before installing new software.

=== Create the Containerfile

A _Containerfile_ is a set of instructions that tell the container engine how to build your container.
If you are familiar with Docker, a Containerfile has the same format as a Dockerfile.
You can read more about Containerfiles here:

* https://docs.podman.io/en/latest/markdown/podman-build.1.html

* https://github.com/containers/common/blob/main/docs/Containerfile.5.md

Before you construct the Containerfile for the JupyterLab container, here's a useful tip about container user environments.

==== Linux User Environments in Containers

One reason that IT organizations prefer Podman is that it can run containers with requiring root access.
As you can imagine, having root access on the machines that run containers is a huge security hole.
In short, most IT organization will not allow root access on production environments.

Podman can run containers without requiring root access.
One way it does this is by using a Linux kernel feature called namespaces, which is widely used in container technologies.
User environments inside a namespace can be grouped and segmented away from the defaul user IDs.
This means your container will run as a different user ID on a target machine than your development user ID.
This is a great feature, but something we may want to change in a development scenario.

==== A Container Method to Map a User ID

The following example shows you how to map your current user ID to that of the running container.
This example uses the ENTRYPOINT feature of a Containerfile to leverage a script that passes your local user ID to the container.

The entrypoint script creates a username inside the container and use an environment variable to set the container's UID to that of the user executing the *podman run* command.

To view an example of this script, see: 
https://github.com/victorgregoriosuse/sle-bci-examples/blob/main/bci-jupyter/entrypoint.sh[entrypoint.sh].

A quick summary of what is happening in this script is important.
It is not important that you understand all the details of this script, unless it is interesting to you.

The entrypoint.sh script uses an environment variable, LOCAL_USERID, to pass an user id number to the container.
As you will see in the Containerfile shown below, you then run the entrypoint.sh script in your container.

=== Build the Container

You build a container through a description file, called the Containerfile.

You can read more about Containerfiles here:

* https://docs.podman.io/en/latest/markdown/podman-build.1.html

* https://github.com/containers/common/blob/main/docs/Containerfile.5.md

Your goal is to create a simple development tool to share your MNIST experiment in JupyterLab.
An example Containfile is shown below.

. Containerfile for JupyterLab with MNIST
+
[source, bash]
----
# https://registry.suse.com/
FROM registry.suse.com/bci/bci-base:latest

ENV ZYPPERCMD="zypper --non-interactive"

RUN $ZYPPERCMD install python3 python3-pip
RUN python3 -m venv /home/virtenv

RUN . /home/virtenv/bin/activate && pip install --upgrade pip
RUN . /home/virtenv/bin/activate && pip install jupyterlab

# Expose the JupyterLab web port
EXPOSE 8888/tcp

# See:  https://denibertovic.com/posts/handling-permissions-with-docker-volumes/
COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN chmod +x /usr/local/bin/entrypoint.sh
ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
CMD [".", "/home/virtenv/bin/activate", "&&", "jupyter-lab"]
----
+
TIP:  For compatibility, Podman will also read files named Dockerfile.

The first element of the Containerfile to note is the FROM clause.
This instruction points to the SUSE Linux Enterprise Base Container Image (SLE BCI).

The RUN clauses will install JupyterLab in the container and the EXPOSE clause will open a TCP/IP port for the service.

You can learn more about containers in the https://documentation.suse.com/container/all/single-html/SLES-container/[SUSE Container Guide].
You might also want to read the section on https://documentation.suse.com/container/all/single-html/SLES-container/#cha-bci[SLE BCI].

Now you will build the container.
You need to create the Contailerfile with the contents described above.
The, use the podman command to build your container image.

NOTE: Use your favorite editor or _vi_ to paste the contents of Containfile.

. Build a container for your JupyerLab & MNIST example
+
[source, bash]
----
cd ~/py-keras
vi Containerfile
podman build .
----
+
TIP: You may have to work through issues with your Containerfile to get your image built properly.

// mkdir -p jupyterlab
// sudo podman run \
// --mount type=bind,source="$(pwd)/jupyterlab",target=/home/jupyterlab \
// --network host \
// --env LOCAL_USERID=$UID \
// --env DEBUG=0 \
// localhost/jupyterlab



=== Run the Container

TBD: tbd

=== Test the Container

TBD: tbd



== Demonstration

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Describe use case / functionality to be demonstrated, followed by
//   the demonstration itself.
// Typical demonstration flow is:
//   1. Prepare (environment for demonstration)
//   2. Perform (actions of demonstration)
//   3. Verify (demonstration worked)
// Depending on the size and complexity of each step,
//   the demonstration can be broken into subsections.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =




== Summary

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Summarize what was covered, including:
//   - Motivation
//   - Installation
//   - Demonstration
// Include any hints about other capabilities.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =




== Additional resources

// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Provide any additional resources that may help the reader
//   continue to explore this topic.
// Use an unordered list for references.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =





// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
// Do not modify below this break.
// = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

++++
<?pdfpagebreak?>
++++


:leveloffset: 0

== Legal notice
include::common_trd_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++


:leveloffset: 0
include::common_gfdl1.2_i.adoc[]

//end
